{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Multivariate-3-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0' # đảm bảo rằng các giá trị băm của đối tượng bất biến (dict, set, chuỗi, tuple...) luôn giống nhau giữa các lần chạy\n",
    "\n",
    "import random as rn\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "rn.seed(3)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')  \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"10Var-szc-rnn.h5\",   # Tên file lưu mô hình\n",
    "    monitor=\"val_loss\",         # Theo dõi val_loss\n",
    "    save_best_only=True,        # Chỉ lưu khi tốt hơn mô hình trước đó\n",
    "    mode=\"min\",                 # Giảm min của val_loss là tốt nhất\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [earlystop, checkpoint] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"SZC_stock_data.csv\"\n",
    "df = pd.read_csv(url, parse_dates= True, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              open   high    low  close   volume\n",
      "time                                           \n",
      "2019-01-15   8.97   8.97   6.58   6.58   109570\n",
      "2019-01-16   6.58   7.03   6.58   7.03    27940\n",
      "2019-01-17   7.51   7.51   7.51   7.51   119080\n",
      "2019-01-18   7.84   7.89   7.51   7.51    50480\n",
      "2019-01-21   7.51   7.51   7.12   7.12    13560\n",
      "...           ...    ...    ...    ...      ...\n",
      "2024-03-14  44.25  45.32  43.33  43.86  2243970\n",
      "2024-03-15  43.67  43.86  42.94  43.86  2592889\n",
      "2024-03-18  43.81  43.81  40.79  41.13  3896580\n",
      "2024-03-19  41.42  41.62  40.79  41.38  1409570\n",
      "2024-03-20  41.33  42.40  40.99  42.06  1099459\n",
      "\n",
      "[1293 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa các dòng có giá trị Volume bằng 0\n",
    "df.drop(df[df['volume']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0.997768\n",
       "high      0.999022\n",
       "low       0.998935\n",
       "close     1.000000\n",
       "volume    0.444012\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ma trận tương quan (ở đây là Pearson tương quan tuyến tính)\n",
    "df.corr()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.293000e+03\n",
      "mean     9.618657e+05\n",
      "std      7.256608e+05\n",
      "min      2.400000e+02\n",
      "25%      4.538290e+05\n",
      "50%      8.436720e+05\n",
      "75%      1.285800e+06\n",
      "max      4.346420e+06\n",
      "Name: volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  Tính toán các thống kê mô tả như trung bình (mean), độ lệch chuẩn (std), min, max, phần trăm phân vị (25%, 50%, 75%).\n",
    "print(df.describe().volume) # Giúp kiểm tra phân bố của Volume, phát hiện các giá trị bất thường (outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vẽ biểu đồ tần suất của Volume\n",
    "df['volume'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phân tích phân bố dữ liệu Volume bằng Histogram**  \n",
    "\n",
    "🔹 `.hist(bins=10)`  \n",
    "- Vẽ **biểu đồ histogram** của cột `Volume` với **10 bins (nhóm dữ liệu)**.  \n",
    "- Giúp trực quan hóa **phân bố dữ liệu**, phát hiện sự **lệch** (skewness) và **giá trị ngoại lai** (outliers).  \n",
    "\n",
    "**Ý nghĩa của biểu đồ histogram**  \n",
    "\n",
    "- **Nếu phân bố lệch phải (right-skewed)** → Dữ liệu có nhiều giá trị nhỏ, một số giá trị rất lớn.  \n",
    "- **Nếu phân bố lệch trái (left-skewed)** → Dữ liệu có nhiều giá trị lớn, một số giá trị rất nhỏ.  \n",
    "- **Nếu có outliers (điểm nằm xa tập trung chính)** → Có thể cần xử lý như **loại bỏ** hoặc **chuẩn hóa dữ liệu**.  \n",
    "\n",
    "**Cách xử lý dữ liệu lệch/skewed**  \n",
    "\n",
    "✅ **Log Transformation** → Dùng `np.log1p(Volume)` để giảm độ lệch.  \n",
    "✅ **Scaling** → Dùng `MinMaxScaler()` hoặc `StandardScaler()` để chuẩn hóa.  \n",
    "✅ **Xử lý outliers** → Loại bỏ hoặc thay thế bằng **giá trị trung bình/median**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bổ sung các chỉ báo kĩ thuật\n",
    "\n",
    "# Tính CMA10\n",
    "df['CMA10'] = df['close'].rolling(window=10, center=True).mean()\n",
    "# Tính SMA10\n",
    "df['SMA10'] = df['close'].rolling(window=10).mean()\n",
    "# Tính SMA50\n",
    "df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "# Tính EMA12 và EMA26\n",
    "df['EMA12'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "df['EMA26'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "# Tính MACD\n",
    "df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "#Tính RSI\n",
    "# Tính giá tăng/giảm\n",
    "delta = df['close'].diff()\n",
    "\n",
    "# Tính giá tăng\n",
    "gain = delta.where(delta > 0, 0)\n",
    "\n",
    "# Tính giá giảm\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "# Tính trung bình động\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "\n",
    "# Tính RS và RSI\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "#Tính CCI\n",
    "# Tính giá trung bình\n",
    "typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "\n",
    "# Tính SMA của giá trung bình\n",
    "sma_typical_price = typical_price.rolling(window=20).mean()\n",
    "\n",
    "# Tính độ lệch chuẩn\n",
    "mean_deviation = typical_price.rolling(window=20).apply(lambda x: np.mean(np.abs(x - x.mean())))\n",
    "\n",
    "# Tính CCI\n",
    "df['CCI'] = (typical_price - sma_typical_price) / (0.015 * mean_deviation)\n",
    "# Tính %K và %D\n",
    "low_min = df['low'].rolling(window=14).min()\n",
    "high_max = df['high'].rolling(window=14).max()\n",
    "\n",
    "df['%K'] = 100 * (df['close'] - low_min) / (high_max - low_min)\n",
    "df['%D'] = df['%K'].rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            open  high   low  close  volume  CMA10  SMA10  SMA50     EMA12  \\\n",
      "time                                                                         \n",
      "2019-01-15  8.97  8.97  6.58   6.58  109570    NaN    NaN    NaN  6.580000   \n",
      "2019-01-16  6.58  7.03  6.58   7.03   27940    NaN    NaN    NaN  6.649231   \n",
      "2019-01-17  7.51  7.51  7.51   7.51  119080    NaN    NaN    NaN  6.781657   \n",
      "2019-01-18  7.84  7.89  7.51   7.51   50480    NaN    NaN    NaN  6.893710   \n",
      "2019-01-21  7.51  7.51  7.12   7.12   13560    NaN    NaN    NaN  6.928524   \n",
      "\n",
      "               EMA26      MACD  RSI  CCI  %K  %D  \n",
      "time                                              \n",
      "2019-01-15  6.580000  0.000000  NaN  NaN NaN NaN  \n",
      "2019-01-16  6.613333  0.035897  NaN  NaN NaN NaN  \n",
      "2019-01-17  6.679753  0.101904  NaN  NaN NaN NaN  \n",
      "2019-01-18  6.741253  0.152457  NaN  NaN NaN NaN  \n",
      "2019-01-21  6.769308  0.159215  NaN  NaN NaN NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1293, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model / Hàm **fit_model_2()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_2(train, val, timesteps, hl, lr, batch, epochs):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(2)\n",
    "    rn.seed(3)\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    # Loop for training data\n",
    "    for i in range(timesteps, train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i][0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "\n",
    "    # Loop for val data\n",
    "    for i in range(timesteps, val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i][0])\n",
    "    X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
    "\n",
    "    # Adding Layers to the model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(X_train.shape[2], input_shape = (X_train.shape[1], X_train.shape[2]), activation = 'relu', return_sequences = True))\n",
    "    for i in range(len(hl)-1):\n",
    "        model.add(SimpleRNN(hl[i], activation = 'relu', return_sequences = True))\n",
    "    model.add(SimpleRNN(hl[-1], activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = optimizers.Adam(learning_rate= lr), loss = 'mean_squared_error')\n",
    "\n",
    "    # Training the data\n",
    "    history = model.fit(X_train, Y_train, epochs = epochs, batch_size = batch, validation_data = (X_val, Y_val), verbose = 0, shuffle = False, callbacks=callbacks_list)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SimpleRNN):\n",
    "            layer.reset_states() #Đảm bảo mỗi lần huấn luyện không bị ảnh hưởng bởi trạng thái cũ của LSTM.\n",
    "    return model, history.history['loss'], history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bước 1: Đặt Seed để đảm bảo tính tái lập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giúp đảm bảo mỗi lần chạy chương trình, các giá trị ngẫu nhiên được tạo ra giống nhau, tránh kết quả huấn luyện thay đổi giữa các lần chạy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp.random.seed(1)\\ntf.random.set_seed(2)\\nrn.seed(3)\\n'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "rn.seed(3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Chuẩn bị dữ liệu huấn luyện (train) và kiểm định (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = []\\nY_train = []\\nX_val = []\\nY_val = []\\n\\nfor i in range(timesteps, train.shape[0]):\\n    X_train.append(train[i-timesteps:i])\\n    Y_train.append(train[i][0])\\nX_train, Y_train = np.array(X_train, Y_train)\\n\\nfor i in range(timesteps, val.shape[0]):\\n    X_val.append(val[i-timesteps:i])\\n    Y_val.append(val[i][0])\\nX_val, Y_val = np.array(X_val, Y_val)  \\n'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for i in range(timesteps, train.shape[0]):\n",
    "    X_train.append(train[i-timesteps:i])\n",
    "    Y_train.append(train[i][0])\n",
    "X_train, Y_train = np.array(X_train, Y_train)\n",
    "\n",
    "for i in range(timesteps, val.shape[0]):\n",
    "    X_val.append(val[i-timesteps:i])\n",
    "    Y_val.append(val[i][0])\n",
    "X_val, Y_val = np.array(X_val, Y_val)  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Xây dựng mô hình RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Xây dựng mô hình RNN\\nmodel = Sequential()\\nmodel.add(SimpleRNN(X_train.shape[2], input_shape= (X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences= True))\\nfor i in range(len(hl)-1):\\n    model.add(SimpleRNN(hl[i], activation='relu', return_sequences= True))\\nmodel.add(SimpleRNN(hl[-1], activation='relu'))\\nmodel.add(Dense(1))\\n\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Xây dựng mô hình RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(X_train.shape[2], input_shape= (X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences= True))\n",
    "for i in range(len(hl)-1):\n",
    "    model.add(SimpleRNN(hl[i], activation='relu', return_sequences= True))\n",
    "model.add(SimpleRNN(hl[-1], activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thêm một lớp **SimpleRNN đầu tiên**:  \n",
    "-   `X_train.shape[2]`: Số đặc trưng (features).\n",
    "-   `input_shape = (X_train.shape[1], X_train.shape[2])`: Định dạng đầu vào (timesteps, số đặc trưng).\n",
    "-   `activation = 'relu'`: Hàm kích hoạt giúp mô hình học phi tuyến tính.\n",
    "-   `return_sequences = True`: Giữ lại toàn bộ chuỗi đầu ra để sử dụng trong các lớp tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Biên dịch mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Biên dịch\\nmodel.compile(optimizer= optimizers.Adam(learning_rate= lr), loss= 'mean_squared_error')\\n\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Biên dịch\n",
    "model.compile(optimizer= optimizers.Adam(learning_rate= lr), loss= 'mean_squared_error')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhistory = model.fit(X_train, Y_train, epochs = epochs, batch_size = batch, validation_data = (X_val, Y_val), verbose = 0, shuffle = False, callbacks=callbacks_list)\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "history = model.fit(X_train, Y_train, epochs = epochs, batch_size = batch, validation_data = (X_val, Y_val), verbose = 0, shuffle = False, callbacks=callbacks_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cấu hình huấn luyện mô hình**\n",
    "\n",
    "🔹 Tham số trong quá trình huấn luyện  \n",
    "\n",
    "✅ `epochs = epochs` → Số vòng huấn luyện  \n",
    "✅ `batch_size = batch` → Kích thước batch  \n",
    "✅ `validation_data = (X_val, Y_val)` → Dữ liệu kiểm định để theo dõi hiệu suất sau mỗi epoch  \n",
    "✅ `verbose = 0` → Không hiển thị log huấn luyện (có thể đặt `verbose = 1` để xem tiến trình)  \n",
    "✅ `shuffle = False` → Không xáo trộn dữ liệu (do chuỗi thời gian có tính thứ tự)  \n",
    "✅ `callbacks = callbacks_list` → Danh sách callback hỗ trợ huấn luyện  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Đảm bảo trạng thái không bị ảnh hưởng khi huấn luyện nhiều lần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor layer in model.layers:\\n    if isinstance(layer, SimpleRNN):\\n        layer.reset_states()\\n'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, SimpleRNN):\n",
    "        layer.reset_states()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 7: Trả về kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nreturn model, history.history['train_loss'], history.history['val_loss']\\n\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "return model, history.history['train_loss'], history.history['val_loss']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search**: Tìm kiếm siêu tham số tối ưu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'timesteps': [30, 40, 50],\n",
    "    'hl': [[40, 35]],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'batch_size': [32, 64],\n",
    "    'num_epochs': [200, 250]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product # Tích đề-các\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm Grid Search\n",
    "def grid_search_rnn(train, val, test, param_grid):\n",
    "# Khởi tạo danh sách lưu kết quả\n",
    "    results = []\n",
    "    best_score = float('inf') # Ban đầu được đặt là vô cùng lớn\n",
    "    best_params = None # Lưu bộ siêu tham số có hiệu suất tốt nhất\n",
    "# Tạo tất cả các tổ hợp tham số\n",
    "    all_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "# Lặp qua từng tổ hợp tham số\n",
    "    for combination in all_combinations:\n",
    "        params = dict(zip(param_names, combination))\n",
    "        timesteps = params['timesteps']\n",
    "        hl = params['hl']\n",
    "        lr = params['lr']\n",
    "        batch_size = params['batch_size']\n",
    "        num_epochs = params['num_epochs']\n",
    "\n",
    "    print(f'Training with param: {params}')\n",
    "# Huấn luyện với fit.model()\n",
    "    model, train_loss, val_loss = fit_model_2(train, val, timesteps, hl, lr,  batch_size, num_epochs)\n",
    "# Đánh giá mô hình với evaluate_model()\n",
    "    mse, rmse, mape, r2, _, _ = evaluate_model_2(model, test, timesteps)\n",
    "# Lưu kết quả\n",
    "    results.append({\n",
    "        'timesteps': timesteps,\n",
    "        'hl': hl,\n",
    "        'lr': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'num_epochs': num_epochs,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R²': r2\n",
    "    })\n",
    "# Cập nhật bộ siêu tham số tốt nhất nếu RMSE cải thiện\n",
    "    if rmse < best_score:\n",
    "        best_score = rmse\n",
    "        best_params = params\n",
    "\n",
    "# Trả về kết quả\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return best_params, best_score, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm **Evaluate_model_2()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Định nghĩa hàm mean_absolute_percentage_error() (MAPE)\\ndef mean_absolute_percentage_error(y_true, y_pred):\\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\\n    return np.mean(np.abs((y_true - y_pred) / y_true))*100\"\\n    '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Định nghĩa hàm mean_absolute_percentage_error() (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_2(model, test, timesteps):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(2)\n",
    "    rn.seed(3)\n",
    "\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Loop for testing data\n",
    "    for i in range(timesteps, test.shape[0]):\n",
    "        X_test.append(test[i-timesteps:i])\n",
    "        Y_test.append(test[i][0])\n",
    "    X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    Y_hat = model.predict(X_test)                         #chứa dự đoán của model dựa trên đầu vào x_test\n",
    "    mse = mean_squared_error(Y_test, Y_hat)\n",
    "    rmse = sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(Y_test, Y_hat)\n",
    "    r2 = r2_score(Y_test, Y_hat)\n",
    "    return mse, rmse, mape, r2, Y_test, Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot chart (vẽ biểu đồ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions\n",
    "def plot_data_2(Y_test,Y_hat):\n",
    "    plt.plot(Y_test, c = 'r')\n",
    "    plt.plot(Y_hat, c = 'y')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(\"Stock Price Prediction using Multivatiate-RNN\")\n",
    "    plt.legend(['Actual','Predicted'], loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training errors: trực quan loss qua các epoch -> thấy qtr học mô hình, xem có overfitting ko\n",
    "def plot_error(train_loss, val_loss):\n",
    "    plt.plot(train_loss, c = 'r')\n",
    "    plt.plot(val_loss, c = 'b')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Train Loss and Validation Loss Curve')\n",
    "    plt.legend(['train', 'val'], loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model building**: Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Trích xuất và trực quan hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 10)\n",
      "            close   CMA10   SMA10    SMA50      EMA12        RSI         CCI  \\\n",
      "time                                                                           \n",
      "2024-03-08  42.01  42.700  42.082  38.1438  41.728648  58.527132   89.439762   \n",
      "2024-03-11  42.11  42.841  42.214  38.2866  41.787318  61.733333   78.471023   \n",
      "2024-03-12  43.76  42.695  42.311  38.4576  42.090807  66.471963  151.814600   \n",
      "2024-03-13  44.15  42.574  42.520  38.6188  42.407606  66.274971  198.091866   \n",
      "2024-03-14  43.86  42.599  42.700  38.7822  42.631051  74.406332  169.247492   \n",
      "\n",
      "                   %K         %D      MACD  \n",
      "time                                        \n",
      "2024-03-08  57.584270  53.491481  1.160930  \n",
      "2024-03-11  60.393258  55.799831  1.105357  \n",
      "2024-03-12  86.560364  68.179298  1.180843  \n",
      "2024-03-13  85.860656  77.604760  1.257639  \n",
      "2024-03-14  72.761194  81.727405  1.280341  \n"
     ]
    }
   ],
   "source": [
    "# Extracting the series\n",
    "series = df[['close', 'CMA10', 'SMA10', 'SMA50', 'EMA12', 'RSI', 'CCI', '%K', '%D', 'MACD']]\n",
    "# Drop rows with NaN values\n",
    "series = series.dropna()\n",
    "\n",
    "# Display the shape and the tail of the cleaned series\n",
    "print(series.shape)\n",
    "print(series.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>CMA10</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>%K</th>\n",
       "      <th>%D</th>\n",
       "      <th>MACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.922185</td>\n",
       "      <td>23.907293</td>\n",
       "      <td>23.800945</td>\n",
       "      <td>23.281065</td>\n",
       "      <td>23.774227</td>\n",
       "      <td>53.859959</td>\n",
       "      <td>23.864276</td>\n",
       "      <td>55.347558</td>\n",
       "      <td>55.334764</td>\n",
       "      <td>0.182251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.051640</td>\n",
       "      <td>10.997325</td>\n",
       "      <td>10.974661</td>\n",
       "      <td>10.724423</td>\n",
       "      <td>10.929829</td>\n",
       "      <td>17.645922</td>\n",
       "      <td>109.921258</td>\n",
       "      <td>30.334386</td>\n",
       "      <td>28.409879</td>\n",
       "      <td>0.985588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.790000</td>\n",
       "      <td>8.319000</td>\n",
       "      <td>8.319000</td>\n",
       "      <td>7.664600</td>\n",
       "      <td>8.479359</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>-314.348887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.034671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.197500</td>\n",
       "      <td>14.148500</td>\n",
       "      <td>13.839000</td>\n",
       "      <td>13.238450</td>\n",
       "      <td>13.736157</td>\n",
       "      <td>41.205512</td>\n",
       "      <td>-62.423004</td>\n",
       "      <td>28.300176</td>\n",
       "      <td>28.838193</td>\n",
       "      <td>-0.209920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.055000</td>\n",
       "      <td>22.756500</td>\n",
       "      <td>22.627000</td>\n",
       "      <td>22.829700</td>\n",
       "      <td>22.904042</td>\n",
       "      <td>54.691071</td>\n",
       "      <td>45.642973</td>\n",
       "      <td>60.917367</td>\n",
       "      <td>60.525771</td>\n",
       "      <td>0.306842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.242500</td>\n",
       "      <td>31.126500</td>\n",
       "      <td>31.060750</td>\n",
       "      <td>31.221150</td>\n",
       "      <td>30.902806</td>\n",
       "      <td>67.240614</td>\n",
       "      <td>108.659315</td>\n",
       "      <td>82.298464</td>\n",
       "      <td>81.481269</td>\n",
       "      <td>0.714092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.610000</td>\n",
       "      <td>53.114000</td>\n",
       "      <td>53.114000</td>\n",
       "      <td>50.160200</td>\n",
       "      <td>52.765743</td>\n",
       "      <td>92.916667</td>\n",
       "      <td>267.139480</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.425287</td>\n",
       "      <td>2.254717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             close        CMA10        SMA10        SMA50        EMA12  \\\n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000   \n",
       "mean     23.922185    23.907293    23.800945    23.281065    23.774227   \n",
       "std      11.051640    10.997325    10.974661    10.724423    10.929829   \n",
       "min       7.790000     8.319000     8.319000     7.664600     8.479359   \n",
       "25%      14.197500    14.148500    13.839000    13.238450    13.736157   \n",
       "50%      23.055000    22.756500    22.627000    22.829700    22.904042   \n",
       "75%      31.242500    31.126500    31.060750    31.221150    30.902806   \n",
       "max      54.610000    53.114000    53.114000    50.160200    52.765743   \n",
       "\n",
       "               RSI          CCI           %K           %D         MACD  \n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000  \n",
       "mean     53.859959    23.864276    55.347558    55.334764     0.182251  \n",
       "std      17.645922   109.921258    30.334386    28.409879     0.985588  \n",
       "min       2.400000  -314.348887     0.000000     0.000000    -4.034671  \n",
       "25%      41.205512   -62.423004    28.300176    28.838193    -0.209920  \n",
       "50%      54.691071    45.642973    60.917367    60.525771     0.306842  \n",
       "75%      67.240614   108.659315    82.298464    81.481269     0.714092  \n",
       "max      92.916667   267.139480   100.000000    99.425287     2.254717  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Chia dữ liệu thành các tập Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "n = series.shape[0]\n",
    "val_size =  test_size = int(n * 0.15)\n",
    "train_size = n - val_size - test_size # Để tránh sai số làm mất dữ liệu\n",
    "\n",
    "# Chia tập dữ liệu theo thứ tự thời gian\n",
    "train_data = series.iloc[:train_size].values\n",
    "val_data = series.iloc[train_size:train_size + val_size].values\n",
    "test_data = series.iloc[(train_size + val_size):].values\n",
    "# Kiểm tra kích thước của từng tập\n",
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Chuẩn hóa dữ liệu bằng MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalisation\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "rn.seed(3)\n",
    "\n",
    "# Chuẩn hóa\n",
    "sc = MinMaxScaler() # Tạo bộ chuẩn hóa MinMaxScaler\n",
    "train = sc.fit_transform(train_data)\n",
    "val = sc.transform(val_data)\n",
    "test = sc.transform(test_data)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Tìm siêu tham số tốt nhất bằng Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with param: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.05648, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.05648 to 0.04746, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 0.04746 to 0.03898, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 0.03898 to 0.03132, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 0.03132 to 0.02459, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 0.02459 to 0.01873, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss improved from 0.01873 to 0.01384, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss improved from 0.01384 to 0.00998, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss improved from 0.00998 to 0.00716, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss improved from 0.00716 to 0.00539, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss improved from 0.00539 to 0.00450, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: val_loss improved from 0.00450 to 0.00421, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00421\n",
      "\n",
      "Epoch 22: val_loss improved from 0.00421 to 0.00419, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: val_loss improved from 0.00419 to 0.00417, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: val_loss improved from 0.00417 to 0.00414, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: val_loss improved from 0.00414 to 0.00410, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: val_loss improved from 0.00410 to 0.00405, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: val_loss improved from 0.00405 to 0.00400, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: val_loss improved from 0.00400 to 0.00394, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: val_loss improved from 0.00394 to 0.00389, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: val_loss improved from 0.00389 to 0.00383, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: val_loss improved from 0.00383 to 0.00376, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: val_loss improved from 0.00376 to 0.00370, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: val_loss improved from 0.00370 to 0.00364, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: val_loss improved from 0.00364 to 0.00358, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: val_loss improved from 0.00358 to 0.00352, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: val_loss improved from 0.00352 to 0.00345, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: val_loss improved from 0.00345 to 0.00338, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: val_loss improved from 0.00338 to 0.00332, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: val_loss improved from 0.00332 to 0.00326, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: val_loss improved from 0.00326 to 0.00321, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41: val_loss improved from 0.00321 to 0.00317, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42: val_loss improved from 0.00317 to 0.00314, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43: val_loss improved from 0.00314 to 0.00310, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44: val_loss improved from 0.00310 to 0.00307, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45: val_loss improved from 0.00307 to 0.00303, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46: val_loss improved from 0.00303 to 0.00299, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47: val_loss improved from 0.00299 to 0.00296, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48: val_loss improved from 0.00296 to 0.00293, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49: val_loss improved from 0.00293 to 0.00289, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: val_loss improved from 0.00289 to 0.00285, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51: val_loss improved from 0.00285 to 0.00281, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52: val_loss improved from 0.00281 to 0.00275, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53: val_loss improved from 0.00275 to 0.00270, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: val_loss improved from 0.00270 to 0.00265, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55: val_loss improved from 0.00265 to 0.00260, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56: val_loss improved from 0.00260 to 0.00256, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57: val_loss improved from 0.00256 to 0.00252, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: val_loss improved from 0.00252 to 0.00248, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59: val_loss improved from 0.00248 to 0.00244, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60: val_loss improved from 0.00244 to 0.00241, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61: val_loss improved from 0.00241 to 0.00238, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62: val_loss improved from 0.00238 to 0.00235, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63: val_loss improved from 0.00235 to 0.00232, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64: val_loss improved from 0.00232 to 0.00229, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65: val_loss improved from 0.00229 to 0.00227, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66: val_loss improved from 0.00227 to 0.00225, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67: val_loss improved from 0.00225 to 0.00223, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68: val_loss improved from 0.00223 to 0.00220, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69: val_loss improved from 0.00220 to 0.00218, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: val_loss improved from 0.00218 to 0.00215, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71: val_loss improved from 0.00215 to 0.00213, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72: val_loss improved from 0.00213 to 0.00210, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73: val_loss improved from 0.00210 to 0.00208, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74: val_loss improved from 0.00208 to 0.00205, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75: val_loss improved from 0.00205 to 0.00203, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: val_loss improved from 0.00203 to 0.00200, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77: val_loss improved from 0.00200 to 0.00198, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78: val_loss improved from 0.00198 to 0.00195, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79: val_loss improved from 0.00195 to 0.00193, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80: val_loss improved from 0.00193 to 0.00191, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81: val_loss improved from 0.00191 to 0.00190, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82: val_loss improved from 0.00190 to 0.00188, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83: val_loss improved from 0.00188 to 0.00186, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84: val_loss improved from 0.00186 to 0.00184, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85: val_loss improved from 0.00184 to 0.00182, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86: val_loss improved from 0.00182 to 0.00180, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87: val_loss improved from 0.00180 to 0.00178, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: val_loss improved from 0.00178 to 0.00176, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 89: val_loss improved from 0.00176 to 0.00175, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90: val_loss improved from 0.00175 to 0.00173, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: val_loss improved from 0.00173 to 0.00172, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92: val_loss improved from 0.00172 to 0.00170, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93: val_loss improved from 0.00170 to 0.00168, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94: val_loss improved from 0.00168 to 0.00167, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95: val_loss improved from 0.00167 to 0.00165, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96: val_loss improved from 0.00165 to 0.00164, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: val_loss improved from 0.00164 to 0.00163, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98: val_loss improved from 0.00163 to 0.00161, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: val_loss improved from 0.00161 to 0.00160, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: val_loss improved from 0.00160 to 0.00158, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 101: val_loss improved from 0.00158 to 0.00157, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: val_loss improved from 0.00157 to 0.00155, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103: val_loss improved from 0.00155 to 0.00154, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: val_loss improved from 0.00154 to 0.00152, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105: val_loss improved from 0.00152 to 0.00151, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106: val_loss improved from 0.00151 to 0.00149, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107: val_loss improved from 0.00149 to 0.00148, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108: val_loss improved from 0.00148 to 0.00147, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109: val_loss improved from 0.00147 to 0.00145, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110: val_loss improved from 0.00145 to 0.00144, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111: val_loss improved from 0.00144 to 0.00143, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: val_loss improved from 0.00143 to 0.00142, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 113: val_loss improved from 0.00142 to 0.00140, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114: val_loss improved from 0.00140 to 0.00139, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 115: val_loss improved from 0.00139 to 0.00138, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116: val_loss improved from 0.00138 to 0.00137, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 117: val_loss improved from 0.00137 to 0.00136, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 118: val_loss improved from 0.00136 to 0.00135, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 119: val_loss improved from 0.00135 to 0.00134, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120: val_loss improved from 0.00134 to 0.00133, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 121: val_loss improved from 0.00133 to 0.00132, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122: val_loss improved from 0.00132 to 0.00131, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123: val_loss improved from 0.00131 to 0.00130, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: val_loss improved from 0.00130 to 0.00128, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 125: val_loss improved from 0.00128 to 0.00127, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126: val_loss improved from 0.00127 to 0.00126, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 127: val_loss improved from 0.00126 to 0.00126, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128: val_loss improved from 0.00126 to 0.00125, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129: val_loss improved from 0.00125 to 0.00124, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss improved from 0.00124 to 0.00123, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 131: val_loss improved from 0.00123 to 0.00123, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132: val_loss improved from 0.00123 to 0.00122, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 133: val_loss improved from 0.00122 to 0.00122, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134: val_loss improved from 0.00122 to 0.00121, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 135: val_loss improved from 0.00121 to 0.00120, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136: val_loss improved from 0.00120 to 0.00119, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 137: val_loss improved from 0.00119 to 0.00119, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138: val_loss improved from 0.00119 to 0.00118, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 139: val_loss improved from 0.00118 to 0.00117, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140: val_loss improved from 0.00117 to 0.00116, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 141: val_loss improved from 0.00116 to 0.00115, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 142: val_loss improved from 0.00115 to 0.00114, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143: val_loss improved from 0.00114 to 0.00114, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144: val_loss improved from 0.00114 to 0.00113, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145: val_loss improved from 0.00113 to 0.00112, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: val_loss improved from 0.00112 to 0.00111, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 147: val_loss improved from 0.00111 to 0.00110, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 148: val_loss improved from 0.00110 to 0.00109, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149: val_loss improved from 0.00109 to 0.00109, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150: val_loss improved from 0.00109 to 0.00108, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 151: val_loss improved from 0.00108 to 0.00107, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152: val_loss improved from 0.00107 to 0.00106, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 153: val_loss improved from 0.00106 to 0.00105, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 154: val_loss improved from 0.00105 to 0.00105, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 155: val_loss improved from 0.00105 to 0.00104, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156: val_loss improved from 0.00104 to 0.00103, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 157: val_loss improved from 0.00103 to 0.00103, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 158: val_loss improved from 0.00103 to 0.00102, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 159: val_loss improved from 0.00102 to 0.00102, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160: val_loss improved from 0.00102 to 0.00101, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 161: val_loss improved from 0.00101 to 0.00101, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 162: val_loss improved from 0.00101 to 0.00100, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 163: val_loss improved from 0.00100 to 0.00099, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 164: val_loss improved from 0.00099 to 0.00099, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 165: val_loss improved from 0.00099 to 0.00098, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 166: val_loss improved from 0.00098 to 0.00098, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 167: val_loss improved from 0.00098 to 0.00097, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 168: val_loss improved from 0.00097 to 0.00096, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 169: val_loss improved from 0.00096 to 0.00096, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 170: val_loss improved from 0.00096 to 0.00095, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 171: val_loss improved from 0.00095 to 0.00095, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 172: val_loss improved from 0.00095 to 0.00095, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 173: val_loss improved from 0.00095 to 0.00094, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174: val_loss improved from 0.00094 to 0.00094, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 175: val_loss improved from 0.00094 to 0.00094, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 176: val_loss improved from 0.00094 to 0.00093, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 177: val_loss improved from 0.00093 to 0.00093, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 178: val_loss improved from 0.00093 to 0.00092, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 179: val_loss improved from 0.00092 to 0.00092, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180: val_loss improved from 0.00092 to 0.00092, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 181: val_loss improved from 0.00092 to 0.00091, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 182: val_loss improved from 0.00091 to 0.00091, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 183: val_loss improved from 0.00091 to 0.00091, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184: val_loss improved from 0.00091 to 0.00090, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 185: val_loss improved from 0.00090 to 0.00090, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186: val_loss improved from 0.00090 to 0.00089, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 187: val_loss improved from 0.00089 to 0.00089, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 188: val_loss improved from 0.00089 to 0.00088, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 189: val_loss improved from 0.00088 to 0.00088, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190: val_loss improved from 0.00088 to 0.00088, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 191: val_loss improved from 0.00088 to 0.00087, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 192: val_loss improved from 0.00087 to 0.00087, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 193: val_loss improved from 0.00087 to 0.00087, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 194: val_loss improved from 0.00087 to 0.00086, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 195: val_loss improved from 0.00086 to 0.00086, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 196: val_loss improved from 0.00086 to 0.00086, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 197: val_loss improved from 0.00086 to 0.00086, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 198: val_loss improved from 0.00086 to 0.00085, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 199: val_loss improved from 0.00085 to 0.00085, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200: val_loss improved from 0.00085 to 0.00084, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 201: val_loss improved from 0.00084 to 0.00084, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202: val_loss improved from 0.00084 to 0.00083, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 203: val_loss improved from 0.00083 to 0.00083, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204: val_loss improved from 0.00083 to 0.00083, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 205: val_loss improved from 0.00083 to 0.00083, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 206: val_loss improved from 0.00083 to 0.00082, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 207: val_loss improved from 0.00082 to 0.00082, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 208: val_loss improved from 0.00082 to 0.00082, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 209: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 210: val_loss improved from 0.00082 to 0.00082, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 211: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 212: val_loss improved from 0.00082 to 0.00081, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 213: val_loss did not improve from 0.00081\n",
      "\n",
      "Epoch 214: val_loss improved from 0.00081 to 0.00081, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 215: val_loss did not improve from 0.00081\n",
      "\n",
      "Epoch 216: val_loss improved from 0.00081 to 0.00080, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 217: val_loss did not improve from 0.00080\n",
      "\n",
      "Epoch 218: val_loss improved from 0.00080 to 0.00080, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 219: val_loss did not improve from 0.00080\n",
      "\n",
      "Epoch 220: val_loss improved from 0.00080 to 0.00080, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 221: val_loss did not improve from 0.00080\n",
      "\n",
      "Epoch 222: val_loss improved from 0.00080 to 0.00079, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 223: val_loss did not improve from 0.00079\n",
      "\n",
      "Epoch 224: val_loss improved from 0.00079 to 0.00079, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 225: val_loss did not improve from 0.00079\n",
      "\n",
      "Epoch 226: val_loss improved from 0.00079 to 0.00078, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 227: val_loss did not improve from 0.00078\n",
      "\n",
      "Epoch 228: val_loss improved from 0.00078 to 0.00077, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 229: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 230: val_loss improved from 0.00077 to 0.00077, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 231: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 232: val_loss improved from 0.00077 to 0.00076, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 233: val_loss did not improve from 0.00076\n",
      "\n",
      "Epoch 234: val_loss improved from 0.00076 to 0.00076, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 235: val_loss did not improve from 0.00076\n",
      "\n",
      "Epoch 236: val_loss improved from 0.00076 to 0.00075, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 237: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 238: val_loss improved from 0.00075 to 0.00075, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 239: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 240: val_loss improved from 0.00075 to 0.00075, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 241: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 242: val_loss improved from 0.00075 to 0.00074, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 243: val_loss did not improve from 0.00074\n",
      "\n",
      "Epoch 244: val_loss improved from 0.00074 to 0.00074, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 245: val_loss did not improve from 0.00074\n",
      "\n",
      "Epoch 246: val_loss improved from 0.00074 to 0.00074, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 247: val_loss did not improve from 0.00074\n",
      "\n",
      "Epoch 248: val_loss improved from 0.00074 to 0.00073, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 249: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 250: val_loss improved from 0.00073 to 0.00073, saving model to 10Var-szc-rnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step\n",
      "   timesteps        hl      lr  batch_size  num_epochs       MSE     RMSE  \\\n",
      "0         50  [40, 35]  0.0001          64         250  0.001056  0.03249   \n",
      "\n",
      "      MAPE        R²  \n",
      "0  0.04694  0.891341  \n",
      "Best parameters: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 250}\n",
      "Best RMSE score: 0.032489627747631054\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score, results_df = grid_search_rnn(train, val, test, param_grid)\n",
    "\n",
    "print(results_df)\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best RMSE score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Huấn luyện mô hình với bộ tham số tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00073\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00073\n"
     ]
    }
   ],
   "source": [
    "timesteps = 50\n",
    "hl = [40, 35]\n",
    "lr = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 250\n",
    "\n",
    "model, train_error, val_error = fit_model_2(train, val, timesteps, hl, lr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Đánh giá mô hình và trực quan hóa kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Vẽ biểu đồ train_loss và val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(train_error, val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Đánh giá mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step\n"
     ]
    }
   ],
   "source": [
    "mse, rmse, mape, r2, true, predicted = evaluate_model_2(model, test, timesteps) #được tính dựa trên bộ dữ liệu đã chuẩn hoá\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.0010555759111796376\n",
      "RMSE = 0.032489627747631054\n",
      "MAPE = 0.046939901762186674\n",
      "R-Squared Score = 0.8913409440413683\n"
     ]
    }
   ],
   "source": [
    "print('MSE = {}'.format(mse))\n",
    "print('RMSE = {}'.format(rmse))\n",
    "print('MAPE = {}'.format(mape))\n",
    "print('R-Squared Score = {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Vẽ đồ thị dự đoán vs thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_2(true, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save('10VAR-szc-rnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Multivariate-3-GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0' # đảm bảo rằng các giá trị băm của đối tượng bất biến (dict, set, chuỗi, tuple...) luôn giống nhau giữa các lần chạy\n",
    "\n",
    "import random as rn\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "rn.seed(3)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')  \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"10Var-szc-gru.h5\",   # Tên file lưu mô hình\n",
    "    monitor=\"val_loss\",         # Theo dõi val_loss\n",
    "    save_best_only=True,        # Chỉ lưu khi tốt hơn mô hình trước đó\n",
    "    mode=\"min\",                 # Giảm min của val_loss là tốt nhất\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [earlystop, checkpoint] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"SZC_stock_data.csv\"\n",
    "df = pd.read_csv(url, parse_dates= True, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-15</th>\n",
       "      <td>8.97</td>\n",
       "      <td>8.97</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.58</td>\n",
       "      <td>109570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16</th>\n",
       "      <td>6.58</td>\n",
       "      <td>7.03</td>\n",
       "      <td>6.58</td>\n",
       "      <td>7.03</td>\n",
       "      <td>27940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-17</th>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>119080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-18</th>\n",
       "      <td>7.84</td>\n",
       "      <td>7.89</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>50480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21</th>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.12</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high   low  close  volume\n",
       "time                                       \n",
       "2019-01-15  8.97  8.97  6.58   6.58  109570\n",
       "2019-01-16  6.58  7.03  6.58   7.03   27940\n",
       "2019-01-17  7.51  7.51  7.51   7.51  119080\n",
       "2019-01-18  7.84  7.89  7.51   7.51   50480\n",
       "2019-01-21  7.51  7.51  7.12   7.12   13560"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa các dòng có giá trị Volume bằng 0\n",
    "df.drop(df[df['volume']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0.997768\n",
       "high      0.999022\n",
       "low       0.998935\n",
       "close     1.000000\n",
       "volume    0.444012\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ma trận tương quan (ở đây là Pearson tương quan tuyến tính)\n",
    "df.corr()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.293000e+03\n",
      "mean     9.618657e+05\n",
      "std      7.256608e+05\n",
      "min      2.400000e+02\n",
      "25%      4.538290e+05\n",
      "50%      8.436720e+05\n",
      "75%      1.285800e+06\n",
      "max      4.346420e+06\n",
      "Name: volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.describe().volume) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGvCAYAAABxUC54AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJVlJREFUeJzt3Q9sVfX9//F323tpCxUKtKzFQluEohn/ikwSJKkDMxZ/VVc0QwHnxKIORJ0hyoQZivxZVRbnYMaUMiFTGWvsho4Jxj9EROYCkb/GWirSUipltnXSFdrSX96fr/esRcAWb7nv9j4fyc3tuefccz+9n97Li8+/E9HS0tIiAAAAhkSGugAAAABnI6AAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAc3zShdXU1EhTU1PQz5uYmCjV1dVBPy++O+rGNurHNurHtnCoH5/PJ3379m3fsdKFaThpbGwM6jkjIiK8c3OZIluoG9uoH9uoH9uon2+iiwcAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOb4OnLw1q1b3a26utptp6SkyK233iqZmZlue/HixXLw4ME2z7n++uvlnnvu8bZPnDghBQUFcuDAAYmJiZGsrCyZPn26REVFBec3ClPNs2+SriaqYFOoiwAA6A4BpV+/fi5MJCcnS0tLi2zbtk2efPJJdxs0aJA7ZvLkyTJt2jTvOT169PB+PnPmjKxYsULi4+Nl6dKlUlNTI6tWrXLhRM8LAADQ4S6ecePGydixY11AGThwoNx+++2uFeSTTz7xjomOjnYBJHDr2bOnt2/Pnj1SUVEh8+bNk7S0NNfyomFmy5Yt0tTURI0AAICOt6C0pq0h77//vpw6dUoyMjK8x999911303By9dVXyy233OJCiyopKZHBgwe7fQFjxoyRNWvWSHl5uaSnp5/ztRobG90tICIiQmJjY72fgylwvmCfF9/U0feYurGN+rGN+rGN+glCQDly5IgsXLjQBQZtPZk/f74bi6ImTpwoCQkJrivos88+kxdffFEqKyvdMaq2trZNOFF9+vTx9p1PcXGxFBUVedsaZPLz8yUxMVE6S1JSknQl5dL1aEtcONRNuKF+bKN+bKN+vkNA0a6dp556Surr62Xnzp2yevVqycvLcyFFB8QGaEtJ3759ZcmSJVJVVfWd3vScnBzJzs72tgMJUwfrBrtrSM+tZdUy6zgbdJ5jx4516Hjqxjbqxzbqx7ZwqR+fz9fuxgXfxZw8EDaGDBkihw4dks2bN7eZqRMwdOhQdx8IKNp6Ulpa2uaYuro6d392y0prfr/f3c6lsypSz9ud/0gsuNj3l7qxjfqxjfqxjfoJ4jooOhal9fiQ1g4fPuzutSVF6VgV7SIKhBK1d+9eN54k0E0EAADQoRaUl156yQ1q1XEmDQ0Nsn37drfuiY5J0VYS3dZZPnFxcS6IrFu3Tq666ipJTU11zx89erQLIjq1eMaMGW7cyYYNG2TKlCnnbSEBAADhp0MBRVs+dMyJrl+i04c1eGg4GTVqlFuAbd++fa67R2f29O/fX8aPHy9Tp071nh8ZGSkLFixws3YWLVrkZvfoQm2t100BAADoUED5xS9+cd592qqig2W/jQ6O+dWvftWRlwUAAGGGa/EAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHN8oS6AReX/b1yoiwAAQFijBQUAAJhDQAEAAOYQUAAAgDmMQUHINM++qcPPKZfQiirYFOISAEB4oAUFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAHTtWTxbt251t+rqaredkpIit956q2RmZrrt06dPy/r162XHjh3S2Ngoo0ePltzcXImPj/fOceLECSkoKJADBw5ITEyMZGVlyfTp0yUqKirYvxsAAAiHgNKvXz8XJpKTk6WlpUW2bdsmTz75pLsNGjRI1q1bJ7t375aHH35YevbsKYWFhbJy5Up54okn3PPPnDkjK1ascIFl6dKlUlNTI6tWrXLhRM8LAADQ4S6ecePGydixY11AGThwoNx+++2uFeSTTz6R+vp6eeutt+TOO++UESNGyJAhQ2TOnDny8ccfS0lJiXv+nj17pKKiQubNmydpaWmu5WXatGmyZcsWaWpqokYAAMB3W6hNW0Pef/99OXXqlGRkZEhZWZk0NzfLyJEjvWMuv/xySUhIcAFFj9H7wYMHt+nyGTNmjKxZs0bKy8slPT39nK+l3UV6C4iIiJDY2Fjv52AK9vnQvfD38e3vDe+RTdSPbdRPEALKkSNHZOHChS4waOvJ/Pnz3ViUw4cPi8/nk169erU5vk+fPlJbW+t+1vvW4SSwP7DvfIqLi6WoqMjb1iCTn58viYmJ0hlCvVop7NLWQ1xYUlJSqIuAC6B+bKN+vkNA0a6dp556ynXp7Ny5U1avXi15eXnSmXJyciQ7O9vbDiRMHawb7K4h0isu5NixY6Eugln62dEv16qqKjdGDbZQP7aFS/34fL52Ny74LubkgYSn40wOHTokmzdvlgkTJriwcPLkyTatKHV1dV6rid6Xlpa2OZ/uD+w7H7/f727n0p0rEvbw99a+94j3yS7qxzbqJ4jroOhYFO3u0bCis3H27dvn7ausrHTTinX8idJ77SIKhBK1d+9eN55Eu4kAAAA63ILy0ksvuUGtOvC1oaFBtm/fLgcPHnRjUnRa8aRJk9w6KHFxcW577dq1LpQEAoqui6JBRKcWz5gxw4072bBhg0yZMuW8LSQAACD8dCigaMuHjjnR9Us0gKSmprpwMmrUKLdfpxhrP5qufaLdPYGF2gIiIyNlwYIFbtbOokWLJDo62i3UplONAQAAAiJaunBnlw6SbT39OBg0YDXl3hjUc6L7iCrYFOoimKWfHZ3lpAOJu/DXSrdF/dgWLvXj9/vbPUiWa/EAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADDH15GDi4uL5YMPPpCjR49Kjx49JCMjQ2bOnCkDBw70jlm8eLEcPHiwzfOuv/56ueeee7ztEydOSEFBgRw4cEBiYmIkKytLpk+fLlFRUcH4nQAAQDgFFA0eU6ZMkSuuuEKam5vl5ZdflqVLl8pvf/tbFzQCJk+eLNOmTfO2NcwEnDlzRlasWCHx8fHuuTU1NbJq1SoXTjSkAAAAdKiLZ+HChXLdddfJoEGDJC0tTebOnetaQ8rKytocFx0d7QJI4NazZ09v3549e6SiokLmzZvnzpGZmenCzJYtW6SpqSl4vxkAAAiPFpSz1dfXu/u4uLg2j7/77rvupuHk6quvlltuucWFFlVSUiKDBw92+wLGjBkja9askfLycklPT//G6zQ2NrpbQEREhMTGxno/B1Owz4fuhb+Pb39veI9son5so36CGFC0q+aFF16Q4cOHu8ARMHHiRElISJB+/frJZ599Ji+++KJUVlbK/Pnz3f7a2to24UT16dPH23e+sS9FRUXetoaY/Px8SUxMlM5Q3ilnRXeQnJwc6iKYl5SUFOoi4AKoH9uonyAElMLCQtfisWTJkm8MiA3Q4NK3b193TFVV1UW/8Tk5OZKdne1tBxJmdXV10LuFSK+4kGPHjoW6CGbpZ0c/4/pZb2lpCXVxcBbqx7ZwqR+fz9fuxgXfxYaT3bt3S15envTv3/+Cxw4dOtTdBwKKtp6Ulpa2Oaaurs7dn92yEuD3+93tXLpzRcIe/t7a9x7xPtlF/dhG/VzkIFl90zSc6FTjxx9/XAYMGPCtzzl8+LC715YUpVOTjxw54oUStXfvXjemJCUlpSPFAQAA3VSHWlA0nGzfvl0eeeQRFygCY0Z0lo5OJdZWEt0/duxYN3BWg8i6devkqquuktTUVHfs6NGjXRDRqcUzZsxw59iwYYObvny+VhIAABBeOhRQtm7d6i3G1tqcOXPc9GPtW9q3b59s3rxZTp065bp/xo8fL1OnTvWOjYyMlAULFrhZO4sWLXKze3ShttbrpgAAgPAW0dKFO7t0kGzr6cfBGqjUlHtjUM+J7iOqYFOoi2CWfnZ0lpMOJO7CXyvdFvVjW7jUj9/vb/cgWa7FAwAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAc3wdObi4uFg++OADOXr0qPTo0UMyMjJk5syZMnDgQO+Y06dPy/r162XHjh3S2Ngoo0ePltzcXImPj/eOOXHihBQUFMiBAwckJiZGsrKyZPr06RIVFRXc3w4AAHT/FpSDBw/KlClTZNmyZbJo0SJpbm6WpUuXSkNDg3fMunXrZNeuXfLwww9LXl6e1NTUyMqVK739Z86ckRUrVkhTU5N77ty5c+Wdd96RP//5z8H9zQAAQHgElIULF8p1110ngwYNkrS0NBcutDWkrKzM7a+vr5e33npL7rzzThkxYoQMGTJE5syZIx9//LGUlJS4Y/bs2SMVFRUyb948d47MzEyZNm2abNmyxYUWAACADnXxnE0DiYqLi3P3GlS0VWXkyJHeMZdffrkkJCS4gKJdQno/ePDgNl0+Y8aMkTVr1kh5ebmkp6d/43W0q0hvARERERIbG+v9HEzBPh+6F/4+vv294T2yifqxjfoJYkDRrpoXXnhBhg8f7gKHqq2tFZ/PJ7169WpzbJ8+fdy+wDGtw0lgf2Df+ca+FBUVedsaYvLz8yUxMVE6Q3mnnBXdQXJycqiLYF5SUlKoi4ALoH5so36CEFAKCwtdi8eSJUuks+Xk5Eh2dra3HUiY1dXVQe8WIr3iQo4dOxbqIpilnx39cq2qqpKWlpZQFwdnoX5sC5f68fl87W5c8F1sONm9e7cbBNu/f3/vcW0Z0cBw8uTJNq0odXV1XquJ3peWlrY5n+4P7DsXv9/vbufSnSsS9vD31r73iPfJLurHNurnIgfJ6pum4USnGj/++OMyYMCANvt1UKxOFd63b5/3WGVlpRtIq+NPlN4fOXLECyVq7969bkxJSkpKR4oDAAC6qQ61oGg42b59uzzyyCMuUATGjPTs2dOti6L3kyZNcuug6MBZ3V67dq0LJYGAouuiaBBZtWqVzJgxw51jw4YNbvry+VpJAABAeOlQQNm6dau7X7x4cZvHdSqxTj9WOsVY+9J07RPt7gks1BYQGRkpCxYscLN2dC2V6Ohot1CbTjUGAABQES1duLNLB8m2nn4cDBqumnJvDOo50X1EFWwKdRHM0s+OznLSgcRd+Gul26J+bAuX+vH7/e0eJMu1eAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDm+UBcA6EqaZ98kXU1UwaZQFwEAOowWFAAA0PVbUA4ePCibNm2STz/9VGpqamT+/PlyzTXXePtXr14t27Zta/Oc0aNHy8KFC73tr776StauXSu7du2SiIgIGT9+vNx1110SExPzXX8fAAAQjgHl1KlTkpaWJpMmTZKnn376nMeMGTNG5syZ878X8bV9mWeffdaFm0WLFklzc7P84Q9/kOeff14efPDBi/kdAABAuAeUzMxMd7vgSX0+iY+PP+e+iooK+fDDD2XFihVyxRVXuMdmzZrltu+44w7p169fR4sEAAC6mU4ZJKvdQLm5udKrVy8ZMWKE3HbbbXLZZZe5fSUlJe7xQDhRI0eOdF09paWlbbqLAhobG90tQI+NjY31fg6mYJ8PCLVL9TcdeB0+QzZRP7ZRP5cgoGj3jo4pGTBggFRVVcnLL78sy5cvl2XLlklkZKTU1tZK79692zwnKipK4uLi3L5zKS4ulqKiIm87PT1d8vPzJTExUTpDeaecFQiN5OTkS/p6SUlJl/T10DHUj23UTycGlGuvvdb7efDgwZKamirz5s2TAwcOuJaSi5GTkyPZ2dnediBhVldXS1NTkwQT6RXdzbFjxy7J6+hnR79c9T8mLS0tl+Q10X7Uj23hUj8+n6/djQudvg7K9773Pde9o2+6BhQdm/Lll1+2OUYHyurMnvONW/H7/e52Lt25IoFguNSfEX09Ppd2UT+2UT+XcB2Uf//73y589O3b121nZGTIyZMnpayszDtm//79rkKGDh3a2cUBAABdQIdbUBoaGlxrSMDx48fl8OHDbgyJ3v7yl7+4MSjaGvL555/Ln/70J9dspWuhqJSUFDdORacVz54923XR6JooEyZMYAYPAAC4uIBy6NAhycvL87bXr1/v7rOyslzgOHLkiFuoTVtJNHCMGjVKpk2b1qaL5oEHHpDCwkJZsmSJt1CbTjUGAABQES1duLNLB8m2nn4cDBqYmnJvDOo5gXC4Fo9+dnTGkA7K7cJfK90W9WNbuNSP3+9v9yBZrsUDAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcX0efcPDgQdm0aZN8+umnUlNTI/Pnz5drrrnG29/S0iIbN26UN998U06ePClXXnml5ObmSnJysnfMV199JWvXrpVdu3ZJRESEjB8/Xu666y6JiYkJ3m8GAADCpwXl1KlTkpaWJnffffc59//tb3+Tf/zjHzJ79mxZvny5REdHy7Jly+T06dPeMc8++6yUl5fLokWLZMGCBfLRRx/J888//91+EwAAEL4BJTMzU2677bY2rSatW082b94sU6dOlR/84AeSmpoq999/v2tp+de//uWOqaiokA8//FDuu+8+GTZsmGthmTVrluzYsUO++OKL4PxWAAAgvLp4LuT48eNSW1sro0aN8h7r2bOnDB06VEpKSuTaa69197169ZIrrrjCO2bkyJGuq6e0tPScwaexsdHdAvTY2NhY7+dgCvb5gFC7VH/TgdfhM2QT9WMb9dPJAUXDierTp0+bx3U7sE/ve/fu3WZ/VFSUxMXFececrbi4WIqKirzt9PR0yc/Pl8TEROkM5Z1yViA0Wo//uhSSkpIu6euhY6gf26ifTgoonSUnJ0eys7O97UDCrK6ulqampqC+FukV3c2xY8cuyevoZ0e/XKuqqlx3L2yhfmwLl/rx+XztblwIakCJj49393V1ddK3b1/vcd3WgbWBY7788ss2z2tubnYzewLPP5vf73e3c+nOFQkEw6X+jOjr8bm0i/qxjfrppHVQBgwY4ELGvn37vMfq6+vd2JKMjAy3rfc6/bisrMw7Zv/+/a5CdKwKAABAh1tQGhoaXBNU64Gxhw8fdmNIEhIS5IYbbpBXXnnF9XtrYNmwYYNrTdFZPSolJUXGjBnjphXrVGTtotE1USZMmCD9+vUL7m8HAADCI6AcOnRI8vLyvO3169e7+6ysLJk7d67cfPPNbq0UDSDaeqLTiB977DHp0aOH95wHHnhACgsLZcmSJd5CbTrVGAAAQEW0dOHOLh0k23r6cTBoYGrKvTGo5wRCKapg0yV5Hf3saMupDsrtwl8r3Rb1Y1u41I/f72/3IFmuxQMAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAMAcAgoAADCHgAIAAMzxhboAADpX8+ybLtlrlXexKzADsIsWFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDm+YJ9w48aNUlRU1OaxgQMHyjPPPON+Pn36tKxfv1527NghjY2NMnr0aMnNzZX4+PhgFwUAAHRRQQ8oatCgQfLrX//a246M/F9Dzbp162T37t3y8MMPS8+ePaWwsFBWrlwpTzzxRGcUBQAAdEGd0sWjgURbRAK33r17u8fr6+vlrbfekjvvvFNGjBghQ4YMkTlz5sjHH38sJSUlnVEUAADQBXVKC0pVVZXce++94vf7JSMjQ6ZPny4JCQlSVlYmzc3NMnLkSO/Yyy+/3O3TgKLHnot2BektICIiQmJjY72fgynY5wPQcXwOO+895b21ifq5BAFl2LBhrlVEx53U1NS48SiPP/6468apra0Vn88nvXr1avOcPn36uH3nU1xc3GZcS3p6uuTn50tiYqJ0hvJOOSuA9kpOTg51EbqtpKSkUBcBF0D9dGJAyczM9H5OTU31Asv7778vPXr0uKhz5uTkSHZ2trcdSJjV1dXS1NQkwUR6BULv2LFjoS5Ct6PfbfqPn7Zwt7S0hLo4CNP68fl87W5c6JQunta0tURbU/RNHzVqlAsUJ0+ebNOKUldXd8FZPNpVpLdz6c4VCYQrPted+97y/tpF/VzCdVAaGhpcONEAooNio6KiZN++fd7+yspKOXHixHnHnwAAgPAT9BYUXeNk3LhxbuCrjkHRdVF0Vs/EiRPdtOJJkya5Y+Li4tz22rVrXTghoAAAgE4LKF988YX87ne/k//85z9uevGVV14py5Yt86Ya6xRj7WvTQbPa3RNYqA0AACAgoqULd3bpINnW04+DQcNTU+6NQT0ngI6JKtgU6iJ0O/rdprOjdAByF/7a77bCpX78fn+7B8lyLR4AAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAAB0/2vxAMB31Tz7JulqWJ4fCC5aUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOQQUAABgDgEFAACYQ0ABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmENAAQAA5hBQAACAOb5QFwAAuoPm2TeJdeXS9UUVbAp1EXCJ0IICAADMoQUFANBldIWWqrPR6nNxaEEBAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDkEFAAAYA4BBQAAmBPShdpef/11efXVV6W2tlZSU1Nl1qxZMnTo0FAWCQAAGBDR0tLSEooX3rFjh6xatUpmz54tw4YNk7///e+yc+dOeeaZZ6RPnz7tOkd1dbU0NjYGtVwRERHSlHtjUM8JAEBXE9UJK+D6/X5JTEy03cXz2muvyeTJk+WHP/yhpKSkuKDSo0cPefvtt0NVJAAAEM5dPE1NTVJWViY/+clPvMciIyNl5MiRUlJS8o3jtZWkdUuJtnLExsaKzxf84uu5I64YHvTzAgDQlUT5/UE/Z0f+3Q5JQPnyyy/lzJkzEh8f3+Zx3a6srPzG8cXFxVJUVORtX3vttfLggw9K3759O6eAz77YOecFAADdZxZPTk6OvPDCC95Nu4OCPfYk4L///a88+uij7h62UDe2UT+2UT+2UT9GWlB69+7tunR09k5run12q0pgUI3eLgUdM/zpp5+6e9hC3dhG/dhG/dhG/RhpQdE+qCFDhsj+/fu9x7TLR7czMjJCUSQAAGBIyNZByc7OltWrV7ugomufbN68WU6dOiXXXXddqIoEAADCPaBMmDDBDZbduHGj69pJS0uTxx577JxdPJeSdiXdeuutl6xLCe1H3dhG/dhG/dhG/RhaqA0AAKBLz+IBAADhhYACAADMIaAAAABzCCgAAMCckM3isej111+XV1991c0qSk1NlVmzZrkp0AitgwcPyqZNm9wiRjU1NTJ//ny55pprQl0stLoUxQcffCBHjx51F/zUtYxmzpwpAwcODHXRICJbt251N736u9KLs+pskczMzFAXDWf561//Ki+99JLccMMN8vOf/1zCHS0oX9uxY4esX7/efXDz8/NdQFm2bJnU1dWFumhhT9fH0Wnod999d6iLgvMEyClTprjPy6JFi6S5uVmWLl0qDQ0NoS4aRKRfv34yffp0+c1vfiMrVqyQESNGyJNPPinl5eWhLhpaKS0tlTfeeMP924P/Q0D52muvvSaTJ0+WH/7wh+5/GHq9H/3f4Ntvvx3qooU9/Z/ebbfdRquJUQsXLnQLLA4aNMgFyblz58qJEyfcFcsReuPGjZOxY8dKcnKya9W6/fbbJSYmRj755JNQFw1f0zD/+9//Xu69917p1atXqItjBgFFRJqamtyX6ciRI73H9FpBul1SUhLSsgFdTX19vbuPi4sLdVFwFr2kyHvvvedaJbmsiB1r1qxx/xEbNWpUqItiCmNQRNyKtvrBPXsVW92urKwMWbmArkY/R3rF8eHDh8vgwYNDXRx87ciRI66lS68Cr60nOo5LW4oRehoYdXyddr+hLVpQAARNYWGhG9vw0EMPhbooaEW7dp566ilZvny5/OhHP3LXQauoqAh1scKedoVqoH/ggQfckAK0RQuKiPTu3dt16ejsndZ0O9TXBgK6UjjZvXu35OXlSf/+/UNdHJx1BfmkpCT3s16g9dChQ+4Crffcc0+oixbWdGiBTsR49NFH27RCfvTRR25Wqc7o0X+bwhUB5esPr35o9+/f7w3E1D8S3f7xj38c6uIBpunlvNauXeumGi9evFgGDBgQ6iLhW+j3m3b3ILR0nOPTTz/d5rHnnnvOtXjdfPPNYR1OFAHla9nZ2a7ZU4OKrn2i/7vQgWQ6OwGhH+FeVVXlbR8/flwOHz7sBmEmJCSEtGz4v5aT7du3yyOPPCKxsbFeS2TPnj1ptjZA/xc+ZswY91nRz5LWlU4N1zEpCC39vJw9Vis6Olouu+wyxnARUP5nwoQJbrDsxo0b3ResTpd87LHH6OIxQJujtdsgQNerUVlZWW5KK0JLFwFT2nrS2pw5cwj4BmgXgv7nSxc51NCo62xoOGHGCKyLaNH2WQAAAEPCu4MLAACYREABAADmEFAAAIA5BBQAAGAOAQUAAJhDQAEAAOYQUAAAgDks1AYAABxdZXjTpk3uCsu6uJ9e+TpwCZj20uXVXn31VXnzzTelurrarYw7ZcoUmTp1aofOQ0ABAACOXuJFV1KfNGnSN64T1F5//OMfZe/evXLHHXe4Jfu/+uord+soAgoAAHAyMzPd7Xz0IpMvv/yyvPfee1JfXy+DBg2SGTNmyPe//323v6KiQt544w1ZuXKlu+ihutgLiBJQAABAuy8OevToUXnooYekb9++7irmy5cvd60tycnJsmvXLhdI9H7ZsmXeVZtnzpzpLvDaEQySBQAA3+rEiRPyzjvvyC9/+Uu56qqrJCkpSW666Sa58sor5e2333bHfP755+64nTt3yv333+8uGlpWVuZaVDqKFhQAAPCtjhw5ImfOnJEHH3ywzeNNTU1e64gOkNVuIL3SfKCL57777pMFCxZIZWWl91h7EFAAAMC3amhokMjISMnPz3f3rcXExLh77faJiopqE0RSUlLcvbasEFAAAEBQ6ewebUGpq6tzXTznMnz4cGlubpaqqirXBaS05UQlJCR06PUYgwIAALxWksOHD7ubOn78uPs50PoxceJEWbVqlfzzn/90+0pLS6W4uFh2797tDYhNT0+X5557zq2louNPCgoKZNSoUR1qPVERLdphBAAAwt6BAwckLy/vG49nZWW5cSU63uSVV16Rbdu2yRdffCG9e/eWYcOGyU9/+lO35onSx9euXevWQomOjnbTln/2s591eBYPAQUAAJhDFw8AADCHgAIAAMwhoAAAAHMIKAAAwBwCCgAAMIeAAgAAzCGgAAAAcwgoAADAHAIKAAAwh4ACAADMIaAAAABzCCgAAECs+f97PqtKvNhiJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['volume'].hist(bins= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bổ sung các chỉ báo kĩ thuật\n",
    "\n",
    "# Tính CMA10\n",
    "df['CMA10'] = df['close'].rolling(window=10, center=True).mean()\n",
    "# Tính SMA10\n",
    "df['SMA10'] = df['close'].rolling(window=10).mean()\n",
    "# Tính SMA50\n",
    "df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "# Tính EMA12 và EMA26\n",
    "df['EMA12'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "df['EMA26'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "# Tính MACD\n",
    "df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "#Tính RSI\n",
    "# Tính giá tăng/giảm\n",
    "delta = df['close'].diff()\n",
    "\n",
    "# Tính giá tăng\n",
    "gain = delta.where(delta > 0, 0)\n",
    "\n",
    "# Tính giá giảm\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "# Tính trung bình động\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "\n",
    "# Tính RS và RSI\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "#Tính CCI\n",
    "# Tính giá trung bình\n",
    "typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "\n",
    "# Tính SMA của giá trung bình\n",
    "sma_typical_price = typical_price.rolling(window=20).mean()\n",
    "\n",
    "# Tính độ lệch chuẩn\n",
    "mean_deviation = typical_price.rolling(window=20).apply(lambda x: np.mean(np.abs(x - x.mean())))\n",
    "\n",
    "# Tính CCI\n",
    "df['CCI'] = (typical_price - sma_typical_price) / (0.015 * mean_deviation)\n",
    "# Tính %K và %D\n",
    "low_min = df['low'].rolling(window=14).min()\n",
    "high_max = df['high'].rolling(window=14).max()\n",
    "\n",
    "df['%K'] = 100 * (df['close'] - low_min) / (high_max - low_min)\n",
    "df['%D'] = df['%K'].rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            open  high   low  close  volume  CMA10  SMA10  SMA50     EMA12  \\\n",
      "time                                                                         \n",
      "2019-01-15  8.97  8.97  6.58   6.58  109570    NaN    NaN    NaN  6.580000   \n",
      "2019-01-16  6.58  7.03  6.58   7.03   27940    NaN    NaN    NaN  6.649231   \n",
      "2019-01-17  7.51  7.51  7.51   7.51  119080    NaN    NaN    NaN  6.781657   \n",
      "2019-01-18  7.84  7.89  7.51   7.51   50480    NaN    NaN    NaN  6.893710   \n",
      "2019-01-21  7.51  7.51  7.12   7.12   13560    NaN    NaN    NaN  6.928524   \n",
      "\n",
      "               EMA26      MACD  RSI  CCI  %K  %D  \n",
      "time                                              \n",
      "2019-01-15  6.580000  0.000000  NaN  NaN NaN NaN  \n",
      "2019-01-16  6.613333  0.035897  NaN  NaN NaN NaN  \n",
      "2019-01-17  6.679753  0.101904  NaN  NaN NaN NaN  \n",
      "2019-01-18  6.741253  0.152457  NaN  NaN NaN NaN  \n",
      "2019-01-21  6.769308  0.159215  NaN  NaN NaN NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1293, 15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model / Hàm **fit_model_3()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_3(train, val, timesteps, hl, lr, batch, epochs):\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(2)\n",
    "    rn.seed(3)\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    for i in range(timesteps, train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i][0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "\n",
    "    for i in range(timesteps, val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i][0])\n",
    "    X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
    "\n",
    "    # Thêm các lớp vào mô hình\n",
    "    model = Sequential()\n",
    "    model.add(GRU(X_train.shape[2], input_shape= (X_train.shape[1], X_train.shape[2]), activation= 'relu', return_sequences= True))\n",
    "    for i in range(len(hl)-1):\n",
    "        model.add(GRU(hl[i], activation='relu', return_sequences= True))\n",
    "    model.add(GRU(hl[-1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Biên dịch\n",
    "    model.compile(optimizer= optimizers.Adam(learning_rate= lr), loss= 'mean_squared_error')\n",
    "\n",
    "    # Huấn luyện dữ liệu\n",
    "    history = model.fit(X_train, Y_train, epochs= epochs, batch_size= batch, validation_data= (X_val, Y_val), verbose= 0, shuffle= False, callbacks= callbacks_list)\n",
    "    \n",
    "    # Đặt lại trạng thái\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, GRU):\n",
    "            layer.reset_states()\n",
    "    \n",
    "    return model, history.history['loss'], history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm **Evaluate_model_3()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_3(model, test, timesteps):\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(2)\n",
    "    \"\"\"\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    for i in range(timesteps, test.shape[0]):\n",
    "        X_test.append(test[i-timesteps:i])\n",
    "        Y_test.append(test[i][0])\n",
    "    X_test, Y_test= np.array(X_test), np.array(Y_test)\n",
    "\n",
    "    # Các chỉ số đánh giá\n",
    "    Y_hat = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, Y_hat)\n",
    "    rmse = sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(Y_test, Y_hat)\n",
    "    r2 = r2_score(Y_test, Y_hat)\n",
    "\n",
    "    return mse, rmse, mape, r2, Y_test, Y_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search**: Tìm kiếm siêu tham số tối ưu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'timesteps': [30, 40, 50],\n",
    "    'hl': [[40, 35]],\n",
    "    'lr': [1e-4, 1e-3],\n",
    "    'batch_size': [32, 64],\n",
    "    'num_epochs': [200, 250]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm grid search\n",
    "def grid_search_rnn(train, val, test, param_grid):\n",
    "    results = []\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    # Tạo tất cả các tổ hợp tham số\n",
    "    all_combinations = list(product(*(param_grid.values())))\n",
    "    param_names = param_grid.keys()\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        # Gán giá trị tham số hiện tại\n",
    "        params = dict(zip(param_names, combination))\n",
    "        hl = params['hl']\n",
    "        lr = params['lr']\n",
    "        batch_size = params['batch_size']\n",
    "        num_epochs = params['num_epochs']\n",
    "\n",
    "        print(f'Training with params: {params}')\n",
    "\n",
    "        # Huấn luyện mô hình\n",
    "        model, train_loss, val_loss = fit_model_3(train, val, timesteps, hl, lr, batch_size, num_epochs)\n",
    "\n",
    "        # Đánh giá mô hình\n",
    "        mse, rmse, mape, r2, _, _ = evaluate_model_3(model, test, timesteps)\n",
    "\n",
    "        # Lưu kết quả\n",
    "        results.append({\n",
    "            'timesteps': timesteps,\n",
    "            'hl': hl,\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'num_epochs': num_epochs,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mape': mape,\n",
    "            'r2': r2\n",
    "        })\n",
    "\n",
    "        # Cập nhật tham số tốt nhất nếu RMSE cải thiện\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_params = params\n",
    "\n",
    "        # Trả về kết quả\n",
    "        results_df = pd.DataFrame(results)\n",
    "        return best_params, best_score, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot chart (vẽ biểu đồ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions\n",
    "def plot_data_3(Y_test, Y_hat):\n",
    "    plt.plot(Y_test, c = 'r')\n",
    "    plt.plot(Y_hat, c = 'y')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(\"Stock Price Prediction using Multivariate-GRU\")\n",
    "    plt.legend(['Actual','Predicted'], loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training errors: trực quan loss qua các epoch -> thấy qtr học mô hình, xem có overfitting ko\n",
    "def plot_error(train_loss, val_loss):\n",
    "    plt.plot(train_loss, c = 'r')\n",
    "    plt.plot(val_loss, c = 'b')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Train Loss and Validation Loss Curve')\n",
    "    plt.legend(['train', 'val'], loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model building**: Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Trích xuất và trực quan hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 10)\n",
      "            close   CMA10   SMA10    SMA50      EMA12        RSI         CCI  \\\n",
      "time                                                                           \n",
      "2024-03-08  42.01  42.700  42.082  38.1438  41.728648  58.527132   89.439762   \n",
      "2024-03-11  42.11  42.841  42.214  38.2866  41.787318  61.733333   78.471023   \n",
      "2024-03-12  43.76  42.695  42.311  38.4576  42.090807  66.471963  151.814600   \n",
      "2024-03-13  44.15  42.574  42.520  38.6188  42.407606  66.274971  198.091866   \n",
      "2024-03-14  43.86  42.599  42.700  38.7822  42.631051  74.406332  169.247492   \n",
      "\n",
      "                   %K         %D      MACD  \n",
      "time                                        \n",
      "2024-03-08  57.584270  53.491481  1.160930  \n",
      "2024-03-11  60.393258  55.799831  1.105357  \n",
      "2024-03-12  86.560364  68.179298  1.180843  \n",
      "2024-03-13  85.860656  77.604760  1.257639  \n",
      "2024-03-14  72.761194  81.727405  1.280341  \n"
     ]
    }
   ],
   "source": [
    "# Extracting the series\n",
    "series = df[['close', 'CMA10', 'SMA10', 'SMA50', 'EMA12', 'RSI', 'CCI', '%K', '%D', 'MACD']]\n",
    "# Drop rows with NaN values\n",
    "series = series.dropna()\n",
    "\n",
    "# Display the shape and the tail of the cleaned series\n",
    "print(series.shape)\n",
    "print(series.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Chia dữ liệu thành các tập Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "n = series.shape[0]\n",
    "val_size =  test_size = int(n * 0.15)\n",
    "train_size = n - val_size - test_size # Để tránh sai số làm mất dữ liệu\n",
    "\n",
    "# Chia tập dữ liệu theo thứ tự thời gian\n",
    "train_data = series.iloc[:train_size].values\n",
    "val_data = series.iloc[train_size:train_size + val_size].values\n",
    "test_data = series.iloc[(train_size + val_size):].values\n",
    "# Kiểm tra kích thước của từng tập\n",
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Chuẩn hóa dữ liệu bằng MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalisation\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "train = sc.fit_transform(train_data)\n",
    "val = sc.transform(val_data)\n",
    "test = sc.transform(test_data)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Tìm siêu tham số tốt nhất bằng Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.07570, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.07570 to 0.06414, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 0.06414 to 0.05369, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_loss improved from 0.05369 to 0.04205, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 0.04205 to 0.03081, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 0.03081 to 0.02139, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_loss improved from 0.02139 to 0.01375, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: val_loss improved from 0.01375 to 0.00786, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss improved from 0.00786 to 0.00381, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: val_loss improved from 0.00381 to 0.00160, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: val_loss improved from 0.00160 to 0.00102, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00102\n",
      "Epoch 91: early stopping\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022F01A0DB20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022F01A0DB20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 523ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022F01A0DB20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022F01A0DB20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step\n",
      "   timesteps        hl      lr  batch_size  num_epochs       mse      rmse  \\\n",
      "0         50  [40, 35]  0.0001          32         200  0.001224  0.034984   \n",
      "\n",
      "       mape        r2  \n",
      "0  0.053613  0.874018  \n",
      "Best parameters: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}\n",
      "Best RMSE score: 0.03498372451419397\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score, results_df = grid_search_rnn(train, val, test, param_grid)\n",
    "\n",
    "print(results_df)\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best RMSE score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Huấn luyện mô hình với bộ tham số tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00102\n",
      "\n",
      "Epoch 8: val_loss improved from 0.00102 to 0.00097, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00097\n",
      "\n",
      "Epoch 51: val_loss improved from 0.00097 to 0.00097, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52: val_loss improved from 0.00097 to 0.00096, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53: val_loss improved from 0.00096 to 0.00095, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: val_loss improved from 0.00095 to 0.00094, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55: val_loss improved from 0.00094 to 0.00094, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56: val_loss improved from 0.00094 to 0.00093, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57: val_loss improved from 0.00093 to 0.00092, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: val_loss improved from 0.00092 to 0.00092, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59: val_loss improved from 0.00092 to 0.00091, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60: val_loss improved from 0.00091 to 0.00090, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61: val_loss improved from 0.00090 to 0.00090, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62: val_loss improved from 0.00090 to 0.00089, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63: val_loss improved from 0.00089 to 0.00088, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64: val_loss improved from 0.00088 to 0.00087, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65: val_loss improved from 0.00087 to 0.00087, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66: val_loss improved from 0.00087 to 0.00086, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67: val_loss improved from 0.00086 to 0.00085, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68: val_loss improved from 0.00085 to 0.00085, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69: val_loss improved from 0.00085 to 0.00084, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: val_loss improved from 0.00084 to 0.00084, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71: val_loss improved from 0.00084 to 0.00084, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72: val_loss improved from 0.00084 to 0.00083, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73: val_loss improved from 0.00083 to 0.00082, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74: val_loss improved from 0.00082 to 0.00082, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75: val_loss improved from 0.00082 to 0.00081, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: val_loss improved from 0.00081 to 0.00081, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77: val_loss improved from 0.00081 to 0.00080, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78: val_loss improved from 0.00080 to 0.00080, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79: val_loss improved from 0.00080 to 0.00079, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80: val_loss improved from 0.00079 to 0.00079, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81: val_loss improved from 0.00079 to 0.00078, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82: val_loss improved from 0.00078 to 0.00078, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83: val_loss improved from 0.00078 to 0.00077, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84: val_loss improved from 0.00077 to 0.00077, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85: val_loss improved from 0.00077 to 0.00077, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86: val_loss improved from 0.00077 to 0.00076, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87: val_loss improved from 0.00076 to 0.00076, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: val_loss improved from 0.00076 to 0.00075, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 89: val_loss improved from 0.00075 to 0.00075, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90: val_loss improved from 0.00075 to 0.00074, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: val_loss improved from 0.00074 to 0.00074, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92: val_loss improved from 0.00074 to 0.00074, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93: val_loss improved from 0.00074 to 0.00073, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94: val_loss improved from 0.00073 to 0.00072, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95: val_loss improved from 0.00072 to 0.00072, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96: val_loss improved from 0.00072 to 0.00071, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: val_loss improved from 0.00071 to 0.00070, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98: val_loss improved from 0.00070 to 0.00070, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: val_loss improved from 0.00070 to 0.00069, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: val_loss improved from 0.00069 to 0.00069, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 101: val_loss improved from 0.00069 to 0.00068, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102: val_loss improved from 0.00068 to 0.00068, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103: val_loss improved from 0.00068 to 0.00068, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: val_loss improved from 0.00068 to 0.00067, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105: val_loss improved from 0.00067 to 0.00067, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106: val_loss improved from 0.00067 to 0.00067, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107: val_loss improved from 0.00067 to 0.00066, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108: val_loss improved from 0.00066 to 0.00066, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109: val_loss improved from 0.00066 to 0.00065, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110: val_loss improved from 0.00065 to 0.00065, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111: val_loss improved from 0.00065 to 0.00064, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: val_loss improved from 0.00064 to 0.00064, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 113: val_loss improved from 0.00064 to 0.00063, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 114: val_loss improved from 0.00063 to 0.00062, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 115: val_loss improved from 0.00062 to 0.00062, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116: val_loss improved from 0.00062 to 0.00062, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 117: val_loss improved from 0.00062 to 0.00061, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 118: val_loss improved from 0.00061 to 0.00061, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 119: val_loss improved from 0.00061 to 0.00060, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120: val_loss improved from 0.00060 to 0.00060, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 121: val_loss improved from 0.00060 to 0.00059, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 122: val_loss improved from 0.00059 to 0.00059, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123: val_loss improved from 0.00059 to 0.00058, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 124: val_loss improved from 0.00058 to 0.00058, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 125: val_loss improved from 0.00058 to 0.00057, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 126: val_loss improved from 0.00057 to 0.00057, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 127: val_loss improved from 0.00057 to 0.00056, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 128: val_loss improved from 0.00056 to 0.00055, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129: val_loss improved from 0.00055 to 0.00055, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss improved from 0.00055 to 0.00054, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 131: val_loss improved from 0.00054 to 0.00054, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 132: val_loss improved from 0.00054 to 0.00054, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 133: val_loss improved from 0.00054 to 0.00053, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 134: val_loss improved from 0.00053 to 0.00053, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 135: val_loss improved from 0.00053 to 0.00053, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 136: val_loss improved from 0.00053 to 0.00053, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 137: val_loss improved from 0.00053 to 0.00052, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 138: val_loss improved from 0.00052 to 0.00052, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 139: val_loss improved from 0.00052 to 0.00052, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140: val_loss improved from 0.00052 to 0.00052, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 141: val_loss improved from 0.00052 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 142: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 144: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 147: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00051\n",
      "\n",
      "Epoch 151: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152: val_loss improved from 0.00051 to 0.00051, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 153: val_loss improved from 0.00051 to 0.00050, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 154: val_loss improved from 0.00050 to 0.00050, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 155: val_loss improved from 0.00050 to 0.00050, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 156: val_loss improved from 0.00050 to 0.00050, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 157: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00050\n",
      "\n",
      "Epoch 184: val_loss improved from 0.00050 to 0.00048, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 185: val_loss improved from 0.00048 to 0.00044, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 186: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00044\n",
      "\n",
      "Epoch 194: val_loss improved from 0.00044 to 0.00042, saving model to 10Var-szc-gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 195: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00042\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00042\n"
     ]
    }
   ],
   "source": [
    "timesteps = 30\n",
    "hl = [40, 35]\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "model, train_loss, val_loss = fit_model_3(train, val, timesteps, hl, lr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Đánh giá mô hình và trực quan hóa kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Vẽ biểu đồ train_loss và val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(train_error, val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Đánh giá mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step\n"
     ]
    }
   ],
   "source": [
    "mse, rmse, mape, r2, true, predicted = evaluate_model_3(model, test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.0008193828573460445\n",
      "RMSE = 0.02862486432013337\n",
      "MAPE = 0.04159674168447461\n",
      "R-Squared Score = 0.9156396651261202\n"
     ]
    }
   ],
   "source": [
    "print('MSE = {}'.format(mse))\n",
    "print('RMSE = {}'.format(rmse))\n",
    "print('MAPE = {}'.format(mape))\n",
    "print('R-Squared Score = {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Vẽ đồ thị dự đoán vs thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_3(true, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save('10VAR-szc-gru.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Multivariate-3-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0' # đảm bảo rằng các giá trị băm của đối tượng bất biến (dict, set, chuỗi, tuple...) luôn giống nhau giữa các lần chạy\n",
    "\n",
    "import random as rn\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "rn.seed(3)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')  \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"10Var_szc_lstm.h5\",   # Tên file lưu mô hình\n",
    "    monitor=\"val_loss\",         # Theo dõi val_loss\n",
    "    save_best_only=True,        # Chỉ lưu khi tốt hơn mô hình trước đó\n",
    "    mode=\"min\",                 # Giảm min của val_loss là tốt nhất\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [earlystop, checkpoint] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"SZC_stock_data.csv\"\n",
    "df = pd.read_csv(url, parse_dates= True, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-15</th>\n",
       "      <td>8.97</td>\n",
       "      <td>8.97</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.58</td>\n",
       "      <td>109570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16</th>\n",
       "      <td>6.58</td>\n",
       "      <td>7.03</td>\n",
       "      <td>6.58</td>\n",
       "      <td>7.03</td>\n",
       "      <td>27940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-17</th>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>119080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-18</th>\n",
       "      <td>7.84</td>\n",
       "      <td>7.89</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>50480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21</th>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.12</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high   low  close  volume\n",
       "time                                       \n",
       "2019-01-15  8.97  8.97  6.58   6.58  109570\n",
       "2019-01-16  6.58  7.03  6.58   7.03   27940\n",
       "2019-01-17  7.51  7.51  7.51   7.51  119080\n",
       "2019-01-18  7.84  7.89  7.51   7.51   50480\n",
       "2019-01-21  7.51  7.51  7.12   7.12   13560"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa các dòng có giá trị Volume bằng 0\n",
    "df.drop(df[df['volume']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open      0.997768\n",
       "high      0.999022\n",
       "low       0.998935\n",
       "close     1.000000\n",
       "volume    0.444012\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ma trận tương quan (ở đây là Pearson tương quan tuyến tính)\n",
    "df.corr()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.293000e+03\n",
      "mean     9.618657e+05\n",
      "std      7.256608e+05\n",
      "min      2.400000e+02\n",
      "25%      4.538290e+05\n",
      "50%      8.436720e+05\n",
      "75%      1.285800e+06\n",
      "max      4.346420e+06\n",
      "Name: volume, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.describe().volume) \n",
    "df['volume'].hist(bins= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bổ sung các chỉ báo kĩ thuật\n",
    "\n",
    "# Tính CMA10\n",
    "df['CMA10'] = df['close'].rolling(window=10, center=True).mean()\n",
    "# Tính SMA10\n",
    "df['SMA10'] = df['close'].rolling(window=10).mean()\n",
    "# Tính SMA50\n",
    "df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "# Tính EMA12 và EMA26\n",
    "df['EMA12'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "df['EMA26'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "# Tính MACD\n",
    "df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "#Tính RSI\n",
    "# Tính giá tăng/giảm\n",
    "delta = df['close'].diff()\n",
    "\n",
    "# Tính giá tăng\n",
    "gain = delta.where(delta > 0, 0)\n",
    "\n",
    "# Tính giá giảm\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "# Tính trung bình động\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "\n",
    "# Tính RS và RSI\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "#Tính CCI\n",
    "# Tính giá trung bình\n",
    "typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "\n",
    "# Tính SMA của giá trung bình\n",
    "sma_typical_price = typical_price.rolling(window=20).mean()\n",
    "\n",
    "# Tính độ lệch chuẩn\n",
    "mean_deviation = typical_price.rolling(window=20).apply(lambda x: np.mean(np.abs(x - x.mean())))\n",
    "\n",
    "# Tính CCI\n",
    "df['CCI'] = (typical_price - sma_typical_price) / (0.015 * mean_deviation)\n",
    "# Tính %K và %D\n",
    "low_min = df['low'].rolling(window=14).min()\n",
    "high_max = df['high'].rolling(window=14).max()\n",
    "\n",
    "df['%K'] = 100 * (df['close'] - low_min) / (high_max - low_min)\n",
    "df['%D'] = df['%K'].rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            open  high   low  close  volume  CMA10  SMA10  SMA50     EMA12  \\\n",
      "time                                                                         \n",
      "2019-01-15  8.97  8.97  6.58   6.58  109570    NaN    NaN    NaN  6.580000   \n",
      "2019-01-16  6.58  7.03  6.58   7.03   27940    NaN    NaN    NaN  6.649231   \n",
      "2019-01-17  7.51  7.51  7.51   7.51  119080    NaN    NaN    NaN  6.781657   \n",
      "2019-01-18  7.84  7.89  7.51   7.51   50480    NaN    NaN    NaN  6.893710   \n",
      "2019-01-21  7.51  7.51  7.12   7.12   13560    NaN    NaN    NaN  6.928524   \n",
      "\n",
      "               EMA26      MACD  RSI  CCI  %K  %D  \n",
      "time                                              \n",
      "2019-01-15  6.580000  0.000000  NaN  NaN NaN NaN  \n",
      "2019-01-16  6.613333  0.035897  NaN  NaN NaN NaN  \n",
      "2019-01-17  6.679753  0.101904  NaN  NaN NaN NaN  \n",
      "2019-01-18  6.741253  0.152457  NaN  NaN NaN NaN  \n",
      "2019-01-21  6.769308  0.159215  NaN  NaN NaN NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1293, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model / Hàm **fit_model_4()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_4(train, val, timesteps, hl, lr, batch, epochs):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    for i in range(timesteps, train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i][0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "\n",
    "    for i in range(timesteps, val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i][0])\n",
    "    X_val, Y_val = np.array(X_val), np.array(Y_val)\n",
    "\n",
    "    # Xây dựng mô hình\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(X_train.shape[2], input_shape= (X_train.shape[1], X_train.shape[2]), activation='relu', return_sequences= True))\n",
    "    for i in range(len(hl)-1):\n",
    "        model.add(LSTM(hl[i], activation='relu', return_sequences= True))\n",
    "    model.add(LSTM(hl[-1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Biên dịch\n",
    "    model.compile(optimizer= optimizers.Adam(learning_rate= lr), loss= 'mean_squared_error')\n",
    "\n",
    "    # Huấn luyện mô hình\n",
    "    history = model.fit(X_train, Y_train, batch_size= batch, epochs= epochs, validation_data= (X_val, Y_val), verbose= 0, shuffle= False, callbacks= callbacks_list)\n",
    "\n",
    "    # Đặt lại trạng thái\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, LSTM):\n",
    "            layer.reset_state()\n",
    "\n",
    "    return model, history.history['loss'], history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm **Evaluate_model_4()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_4(model, test, timesteps):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    for i in range(timesteps, test.shape[0]):\n",
    "        X_test.append(test[i-timesteps:i])\n",
    "        Y_test.append(test[i][0])\n",
    "    X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "\n",
    "    # Các chỉ số\n",
    "    Y_hat = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, Y_hat)\n",
    "    rmse = sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(Y_test, Y_hat)\n",
    "    r2 = r2_score(Y_test, Y_hat)\n",
    "\n",
    "    return mse, rmse, mape, r2, Y_test, Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search**: Tìm kiếm siêu tham số tối ưu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'timesteps': [30, 40, 50],  # Số giá trị trước đó để dự đoán\n",
    "    'hl': [ [40, 35]], # Cấu trúc lớp ẩn\n",
    "    'lr': [1e-3, 1e-4],  # Tốc độ học\n",
    "    'batch_size': [32, 64],  # Kích thước batch\n",
    "    'num_epochs': [200, 250],  # Số epoch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm Grid Search\n",
    "def grid_search_rnn(train, val, test, param_grid):\n",
    "    results = []  # Lưu kết quả của từng tổ hợp tham số\n",
    "    best_score = float('inf')  # Lưu RMSE tốt nhất\n",
    "    best_params = None  # Lưu bộ tham số tốt nhất\n",
    "\n",
    "    # Tạo tất cả các tổ hợp tham số\n",
    "    all_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        # Gán giá trị tham số hiện tại\n",
    "        params = dict(zip(param_names, combination))\n",
    "        timesteps = params['timesteps']\n",
    "        hl = params['hl']\n",
    "        lr = params['lr']\n",
    "        batch_size = params['batch_size']\n",
    "        num_epochs = params['num_epochs']\n",
    "\n",
    "        print(f\"Training with params: {params}\")\n",
    "\n",
    "        # Huấn luyện mô hình\n",
    "        model, train_loss, val_loss = fit_model_4(\n",
    "            train, val, timesteps, hl, lr, batch_size, num_epochs\n",
    "        )\n",
    "\n",
    "        # Đánh giá mô hình\n",
    "        mse, rmse, mape, r2, _, _ = evaluate_model_4(model, test, timesteps)\n",
    "\n",
    "        # Lưu kết quả\n",
    "        results.append({\n",
    "            'timesteps': timesteps,\n",
    "            'hl': hl,\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'num_epochs': num_epochs,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE': mape,\n",
    "            'R²': r2\n",
    "        })\n",
    "\n",
    "        # Cập nhật tham số tốt nhất nếu RMSE cải thiện\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_params = params\n",
    "\n",
    "    # Trả về kết quả\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return best_params, best_score, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot chart (vẽ biểu đồ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions\n",
    "def plot_data_4(Y_test, Y_hat):\n",
    "    plt.plot(Y_test, c = 'r')\n",
    "    plt.plot(Y_hat, c = 'y')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title('Stock Prediction Graph using Multivariate-LSTM model')\n",
    "    plt.legend(['Actual', 'Predicted'], loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training errors: trực quan loss qua các epoch -> thấy qtr học mô hình, xem có overfitting ko\n",
    "def plot_error(train_loss, val_loss):\n",
    "    plt.plot(train_loss, c = 'r')\n",
    "    plt.plot(val_loss, c = 'b')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Train Loss and Validation Loss Curve')\n",
    "    plt.legend(['train', 'val'], loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model building**: Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Trích xuất và trực quan hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1240, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>CMA10</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>RSI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>%K</th>\n",
       "      <th>%D</th>\n",
       "      <th>MACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.922185</td>\n",
       "      <td>23.907293</td>\n",
       "      <td>23.800945</td>\n",
       "      <td>23.281065</td>\n",
       "      <td>23.774227</td>\n",
       "      <td>53.859959</td>\n",
       "      <td>23.864276</td>\n",
       "      <td>55.347558</td>\n",
       "      <td>55.334764</td>\n",
       "      <td>0.182251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.051640</td>\n",
       "      <td>10.997325</td>\n",
       "      <td>10.974661</td>\n",
       "      <td>10.724423</td>\n",
       "      <td>10.929829</td>\n",
       "      <td>17.645922</td>\n",
       "      <td>109.921258</td>\n",
       "      <td>30.334386</td>\n",
       "      <td>28.409879</td>\n",
       "      <td>0.985588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.790000</td>\n",
       "      <td>8.319000</td>\n",
       "      <td>8.319000</td>\n",
       "      <td>7.664600</td>\n",
       "      <td>8.479359</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>-314.348887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.034671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.197500</td>\n",
       "      <td>14.148500</td>\n",
       "      <td>13.839000</td>\n",
       "      <td>13.238450</td>\n",
       "      <td>13.736157</td>\n",
       "      <td>41.205512</td>\n",
       "      <td>-62.423004</td>\n",
       "      <td>28.300176</td>\n",
       "      <td>28.838193</td>\n",
       "      <td>-0.209920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.055000</td>\n",
       "      <td>22.756500</td>\n",
       "      <td>22.627000</td>\n",
       "      <td>22.829700</td>\n",
       "      <td>22.904042</td>\n",
       "      <td>54.691071</td>\n",
       "      <td>45.642973</td>\n",
       "      <td>60.917367</td>\n",
       "      <td>60.525771</td>\n",
       "      <td>0.306842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.242500</td>\n",
       "      <td>31.126500</td>\n",
       "      <td>31.060750</td>\n",
       "      <td>31.221150</td>\n",
       "      <td>30.902806</td>\n",
       "      <td>67.240614</td>\n",
       "      <td>108.659315</td>\n",
       "      <td>82.298464</td>\n",
       "      <td>81.481269</td>\n",
       "      <td>0.714092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.610000</td>\n",
       "      <td>53.114000</td>\n",
       "      <td>53.114000</td>\n",
       "      <td>50.160200</td>\n",
       "      <td>52.765743</td>\n",
       "      <td>92.916667</td>\n",
       "      <td>267.139480</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.425287</td>\n",
       "      <td>2.254717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             close        CMA10        SMA10        SMA50        EMA12  \\\n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000   \n",
       "mean     23.922185    23.907293    23.800945    23.281065    23.774227   \n",
       "std      11.051640    10.997325    10.974661    10.724423    10.929829   \n",
       "min       7.790000     8.319000     8.319000     7.664600     8.479359   \n",
       "25%      14.197500    14.148500    13.839000    13.238450    13.736157   \n",
       "50%      23.055000    22.756500    22.627000    22.829700    22.904042   \n",
       "75%      31.242500    31.126500    31.060750    31.221150    30.902806   \n",
       "max      54.610000    53.114000    53.114000    50.160200    52.765743   \n",
       "\n",
       "               RSI          CCI           %K           %D         MACD  \n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000  \n",
       "mean     53.859959    23.864276    55.347558    55.334764     0.182251  \n",
       "std      17.645922   109.921258    30.334386    28.409879     0.985588  \n",
       "min       2.400000  -314.348887     0.000000     0.000000    -4.034671  \n",
       "25%      41.205512   -62.423004    28.300176    28.838193    -0.209920  \n",
       "50%      54.691071    45.642973    60.917367    60.525771     0.306842  \n",
       "75%      67.240614   108.659315    82.298464    81.481269     0.714092  \n",
       "max      92.916667   267.139480   100.000000    99.425287     2.254717  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the series\n",
    "series = df[['close', 'CMA10', 'SMA10', 'SMA50', 'EMA12', 'RSI', 'CCI', '%K', '%D', 'MACD']]\n",
    "# Drop rows with NaN values\n",
    "series = series.dropna()\n",
    "\n",
    "# Display the shape and the tail of the cleaned series\n",
    "print(series.shape)\n",
    "series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Chia dữ liệu thành các tập Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = series.shape[0]\n",
    "val_size =  test_size = int(n * 0.15)\n",
    "train_size = n - val_size - test_size # Để tránh sai số làm mất dữ liệu\n",
    "\n",
    "# Chia tập dữ liệu theo thứ tự thời gian\n",
    "train_data = series.iloc[:train_size].values\n",
    "val_data = series.iloc[train_size:train_size + val_size].values\n",
    "test_data = series.iloc[(train_size + val_size):].values\n",
    "# Kiểm tra kích thước của từng tập\n",
    "print(train_data.shape, val_data.shape, test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Chuẩn hóa dữ liệu bằng MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 10) (186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "train = sc.fit_transform(train_data)\n",
    "val = sc.transform(val_data)\n",
    "test = sc.transform(test_data)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Tìm siêu tham số tốt nhất bằng Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.01689, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.01689 to 0.00142, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00142\n",
      "\n",
      "Epoch 53: val_loss improved from 0.00142 to 0.00117, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: val_loss improved from 0.00117 to 0.00098, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55: val_loss improved from 0.00098 to 0.00087, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00087\n",
      "\n",
      "Epoch 68: val_loss improved from 0.00087 to 0.00087, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69: val_loss improved from 0.00087 to 0.00085, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: val_loss improved from 0.00085 to 0.00082, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00082\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00082 to 0.00080, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91: val_loss did not improve from 0.00080\n",
      "\n",
      "Epoch 92: val_loss improved from 0.00080 to 0.00077, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00077\n",
      "\n",
      "Epoch 99: val_loss improved from 0.00077 to 0.00075, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00075\n",
      "\n",
      "Epoch 103: val_loss improved from 0.00075 to 0.00070, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 140: val_loss improved from 0.00070 to 0.00070, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 141: val_loss did not improve from 0.00070\n",
      "\n",
      "Epoch 142: val_loss improved from 0.00070 to 0.00067, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143: val_loss did not improve from 0.00067\n",
      "\n",
      "Epoch 144: val_loss improved from 0.00067 to 0.00066, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 145: val_loss improved from 0.00066 to 0.00064, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00064\n",
      "\n",
      "Epoch 151: val_loss improved from 0.00064 to 0.00063, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 152: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 189: val_loss improved from 0.00063 to 0.00063, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 190: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00063\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00063\n",
      "\n",
      "Epoch 98: val_loss improved from 0.00063 to 0.00059, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: val_loss improved from 0.00059 to 0.00058, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00058\n",
      "\n",
      "Epoch 111: val_loss improved from 0.00058 to 0.00056, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00056\n",
      "\n",
      "Epoch 129: val_loss improved from 0.00056 to 0.00052, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00052\n",
      "\n",
      "Epoch 148: val_loss improved from 0.00052 to 0.00047, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00047\n",
      "\n",
      "Epoch 201: val_loss improved from 0.00047 to 0.00039, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 202: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00039\n",
      "\n",
      "Epoch 209: val_loss improved from 0.00039 to 0.00034, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 210: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00034\n",
      "\n",
      "Epoch 224: val_loss improved from 0.00034 to 0.00032, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 225: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 238: val_loss improved from 0.00032 to 0.00032, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 239: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00032\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "Epoch 82: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "Epoch 86: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00032\n",
      "Epoch 130: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00032\n",
      "Epoch 131: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "Epoch 92: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step\n",
      "Training with params: {'timesteps': 30, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "Epoch 92: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00032\n",
      "Epoch 189: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 450ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00032\n",
      "\n",
      "Epoch 179: val_loss improved from 0.00032 to 0.00031, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00031\n",
      "\n",
      "Epoch 200: val_loss improved from 0.00031 to 0.00029, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 201: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 215: val_loss improved from 0.00029 to 0.00026, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 216: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00026\n",
      "\n",
      "Epoch 230: val_loss improved from 0.00026 to 0.00025, saving model to 10Var_szc_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 231: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00025\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "Epoch 94: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00025\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "Epoch 159: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "Epoch 127: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "Epoch 100: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step\n",
      "Training with params: {'timesteps': 40, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00025\n",
      "Epoch 167: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00025\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.00025\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "Epoch 92: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "Epoch 119: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00025\n",
      "Epoch 176: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 32, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00025\n",
      "Epoch 159: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00025\n",
      "Epoch 147: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step\n",
      "Training with params: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 250}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00025\n",
      "Epoch 136: early stopping\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n",
      "    timesteps        hl      lr  batch_size  num_epochs       MSE      RMSE  \\\n",
      "0          30  [40, 35]  0.0010          32         200  0.004589  0.067742   \n",
      "1          30  [40, 35]  0.0010          32         250  0.001562  0.039521   \n",
      "2          30  [40, 35]  0.0010          64         200  0.002421  0.049200   \n",
      "3          30  [40, 35]  0.0010          64         250  0.001588  0.039855   \n",
      "4          30  [40, 35]  0.0001          32         200  0.001490  0.038601   \n",
      "5          30  [40, 35]  0.0001          32         250  0.001425  0.037753   \n",
      "6          30  [40, 35]  0.0001          64         200  0.001995  0.044665   \n",
      "7          30  [40, 35]  0.0001          64         250  0.002158  0.046459   \n",
      "8          40  [40, 35]  0.0010          32         200  0.000849  0.029137   \n",
      "9          40  [40, 35]  0.0010          32         250  0.001992  0.044636   \n",
      "10         40  [40, 35]  0.0010          64         200  0.002414  0.049131   \n",
      "11         40  [40, 35]  0.0010          64         250  0.000969  0.031136   \n",
      "12         40  [40, 35]  0.0001          32         200  0.003176  0.056358   \n",
      "13         40  [40, 35]  0.0001          32         250  0.002420  0.049197   \n",
      "14         40  [40, 35]  0.0001          64         200  0.002072  0.045518   \n",
      "15         40  [40, 35]  0.0001          64         250  0.001699  0.041216   \n",
      "16         50  [40, 35]  0.0010          32         200  0.001289  0.035903   \n",
      "17         50  [40, 35]  0.0010          32         250  0.000596  0.024415   \n",
      "18         50  [40, 35]  0.0010          64         200  0.001245  0.035286   \n",
      "19         50  [40, 35]  0.0010          64         250  0.001068  0.032683   \n",
      "20         50  [40, 35]  0.0001          32         200  0.001938  0.044022   \n",
      "21         50  [40, 35]  0.0001          32         250  0.001747  0.041803   \n",
      "22         50  [40, 35]  0.0001          64         200  0.001681  0.041004   \n",
      "23         50  [40, 35]  0.0001          64         250  0.001752  0.041860   \n",
      "\n",
      "        MAPE        R²  \n",
      "0   0.116863  0.527531  \n",
      "1   0.067188  0.839190  \n",
      "2   0.072984  0.750782  \n",
      "3   0.059697  0.836462  \n",
      "4   0.058125  0.846590  \n",
      "5   0.057004  0.853254  \n",
      "6   0.066375  0.794607  \n",
      "7   0.072707  0.777774  \n",
      "8   0.043483  0.914628  \n",
      "9   0.074099  0.799639  \n",
      "10  0.072811  0.757256  \n",
      "11  0.047749  0.902507  \n",
      "12  0.088232  0.680595  \n",
      "13  0.076654  0.756608  \n",
      "14  0.068726  0.791646  \n",
      "15  0.063588  0.829169  \n",
      "16  0.056569  0.867313  \n",
      "17  0.035372  0.938638  \n",
      "18  0.053187  0.871835  \n",
      "19  0.049544  0.890043  \n",
      "20  0.064894  0.800509  \n",
      "21  0.064060  0.820119  \n",
      "22  0.061954  0.826927  \n",
      "23  0.061202  0.819621  \n",
      "Best parameters: {'timesteps': 50, 'hl': [40, 35], 'lr': 0.001, 'batch_size': 32, 'num_epochs': 250}\n",
      "Best RMSE score: 0.02441524689522165\n"
     ]
    }
   ],
   "source": [
    "best_params, best_score, results_df = grid_search_rnn(train, val, test, param_grid)\n",
    "\n",
    "print(results_df)\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best RMSE score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Huấn luyện mô hình với bộ tham số tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\84368\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00025\n",
      "Epoch 90: early stopping\n"
     ]
    }
   ],
   "source": [
    "timesteps = 50\n",
    "hl = [40, 35]\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 250\n",
    "\n",
    "model, train_error, val_error = fit_model_4(train, val, timesteps, hl, lr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Đánh giá mô hình và trực quan hóa kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Vẽ biểu đồ train_loss và val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(train_error, val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Đánh giá mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 265ms/step\n"
     ]
    }
   ],
   "source": [
    "mse, rmse, mape, r2, true, predicted = evaluate_model_4(model, test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.000826151321881605\n",
      "RMSE = 0.028742848186663846\n",
      "MAPE = 0.04389271305944009\n",
      "R-Squared Score = 0.9149574921482326\n"
     ]
    }
   ],
   "source": [
    "print('MSE = {}'.format(mse))\n",
    "print('RMSE = {}'.format(rmse))\n",
    "print('MAPE = {}'.format(mape))\n",
    "print('R-Squared Score = {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Vẽ đồ thị dự đoán vs thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_4(true, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save('10VAR-szc-lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
